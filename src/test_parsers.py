#!/usr/bin/env python3
"""
CLI ê¸°ë°˜ Parser í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

3ê°œì˜ Parserë¥¼ ë¹„êµ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:
1. VLM Parser (Qwen3-VL-2B-Instruct)
2. OCR Parser - Text (pdfplumber)
3. OCR Parser - Image (Docling + RapidOCR)

Usage:
    python -m src.test_parsers --pdf data/sample_data.pdf --gt data/ground_truth.md
    python -m src.test_parsers --pdf data/sample_data.pdf  # GT ì—†ì´ íŒŒì‹±ë§Œ
"""

import argparse
import sys
import time
import re
from pathlib import Path


# =============================================================================
# Text Normalization (for fair comparison)
# =============================================================================

def normalize_text(text: str) -> str:
    """í…ìŠ¤íŠ¸ ì •ê·œí™” - CER/WER ë¹„êµë¥¼ ìœ„í•œ ì „ì²˜ë¦¬

    - ë§ˆí¬ë‹¤ìš´ ë¬¸ë²• ì œê±°
    - ë‹¤ì¤‘ ê³µë°±/ì¤„ë°”ê¿ˆ ì •ê·œí™”
    - ì•ë’¤ ê³µë°± ì œê±°
    """
    if not text:
        return ""

    result = text

    # ë§ˆí¬ë‹¤ìš´ í—¤ë” ì œê±°
    result = re.sub(r'^#{1,6}\s+', '', result, flags=re.MULTILINE)

    # Bold/Italic ì œê±°
    result = re.sub(r'\*\*\*(.+?)\*\*\*', r'\1', result)
    result = re.sub(r'\*\*(.+?)\*\*', r'\1', result)
    result = re.sub(r'\*(.+?)\*', r'\1', result)
    result = re.sub(r'___(.+?)___', r'\1', result)
    result = re.sub(r'__(.+?)__', r'\1', result)
    result = re.sub(r'_(.+?)_', r'\1', result)

    # ë§í¬ ì œê±°
    result = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', result)

    # ë¦¬ìŠ¤íŠ¸ ë§ˆì»¤ ì œê±°
    result = re.sub(r'^[\s]*[-*+]\s+', '', result, flags=re.MULTILINE)
    result = re.sub(r'^[\s]*\d+\.\s+', '', result, flags=re.MULTILINE)

    # í…Œì´ë¸” íŒŒì´í”„ ì œê±°
    result = re.sub(r'\|', ' ', result)

    # ë‹¤ì¤‘ ê³µë°± ì •ê·œí™”
    result = re.sub(r'[ \t]+', ' ', result)
    result = re.sub(r'\n{2,}', '\n', result)

    # ê° ì¤„ ì•ë’¤ ê³µë°± ì œê±°
    lines = [line.strip() for line in result.split('\n')]
    lines = [line for line in lines if line]

    return '\n'.join(lines).strip()


# =============================================================================
# Tokenizer
# =============================================================================

def get_tokenizer(tokenizer_type: str = "whitespace"):
    """í† í¬ë‚˜ì´ì € ë°˜í™˜

    Args:
        tokenizer_type: "whitespace", "mecab", "okt"

    Returns:
        tokenize í•¨ìˆ˜
    """
    if tokenizer_type == "mecab":
        try:
            from konlpy.tag import Mecab
            mecab = Mecab()
            print("âœ“ Mecab í† í¬ë‚˜ì´ì € ì‚¬ìš©")
            return mecab.morphs
        except ImportError:
            print("âš ï¸ konlpyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. whitespaceë¡œ fallback")
            return lambda x: x.split()
        except Exception as e:
            print(f"âš ï¸ Mecab ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. whitespaceë¡œ fallback")
            return lambda x: x.split()

    elif tokenizer_type == "okt":
        try:
            from konlpy.tag import Okt
            okt = Okt()
            print("âœ“ Okt í† í¬ë‚˜ì´ì € ì‚¬ìš© (ìˆœìˆ˜ Python, ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì—†ìŒ)")
            return okt.morphs
        except ImportError:
            print("âš ï¸ konlpyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. whitespaceë¡œ fallback")
            return lambda x: x.split()
        except Exception as e:
            print(f"âš ï¸ Okt ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. whitespaceë¡œ fallback")
            return lambda x: x.split()

    else:
        return lambda x: x.split()


# =============================================================================
# CER/WER Calculation (using jiwer library)
# =============================================================================

import jiwer


def calculate_cer(hypothesis: str, reference: str) -> dict:
    """Character Error Rate ê³„ì‚° (jiwer ì‚¬ìš©)

    Returns:
        dict with cer, substitutions, deletions, insertions
    """
    if not reference:
        return {"cer": 0.0 if not hypothesis else float('inf')}

    if not hypothesis:
        return {
            "cer": 1.0,
            "substitutions": 0,
            "deletions": len(reference),
            "insertions": 0
        }

    # jiwer.cer: reference first, hypothesis second
    cer_value = jiwer.cer(reference, hypothesis)

    # ìƒì„¸ ì •ë³´
    output = jiwer.process_characters(reference, hypothesis)

    return {
        "cer": cer_value,
        "substitutions": output.substitutions,
        "deletions": output.deletions,
        "insertions": output.insertions,
        "hits": output.hits
    }


def calculate_wer(hypothesis: str, reference: str, tokenizer=None) -> dict:
    """Word Error Rate ê³„ì‚° (jiwer ì‚¬ìš©)

    Args:
        hypothesis: íŒŒì„œ ì¶œë ¥ í…ìŠ¤íŠ¸
        reference: Ground Truth í…ìŠ¤íŠ¸
        tokenizer: í† í¬ë‚˜ì´ì € í•¨ìˆ˜ (Noneì´ë©´ ê³µë°± ë¶„ë¦¬)

    Returns:
        dict with wer, substitutions, deletions, insertions
    """
    if tokenizer is None:
        tokenizer = lambda x: x.split()

    if not reference:
        return {"wer": 0.0 if not hypothesis else float('inf')}

    # í† í°í™”
    ref_tokens = tokenizer(reference)
    hyp_tokens = tokenizer(hypothesis) if hypothesis else []

    if not hyp_tokens:
        return {
            "wer": 1.0,
            "substitutions": 0,
            "deletions": len(ref_tokens),
            "insertions": 0,
            "ref_tokens": len(ref_tokens),
            "hyp_tokens": 0
        }

    # í† í°ì„ ê³µë°±ìœ¼ë¡œ ì—°ê²°í•˜ì—¬ jiwerì— ì „ë‹¬
    ref_str = " ".join(ref_tokens)
    hyp_str = " ".join(hyp_tokens)

    # jiwer.wer: reference first, hypothesis second
    wer_value = jiwer.wer(ref_str, hyp_str)

    # ìƒì„¸ ì •ë³´
    output = jiwer.process_words(ref_str, hyp_str)

    return {
        "wer": wer_value,
        "substitutions": output.substitutions,
        "deletions": output.deletions,
        "insertions": output.insertions,
        "hits": output.hits,
        "ref_tokens": len(ref_tokens),
        "hyp_tokens": len(hyp_tokens)
    }


# =============================================================================
# Parser Tests
# =============================================================================

def test_vlm_parser(pdf_bytes: bytes, verbose: bool = False) -> dict:
    """VLM Parser í…ŒìŠ¤íŠ¸"""
    from parsers.vlm_parser import VLMParser
    from parsers.ocr_parser import ImageOCRParser

    print("\n" + "=" * 60)
    print("ğŸ¤– VLM Parser (Qwen3-VL-2B-Instruct)")
    print("=" * 60)

    start_time = time.time()

    # PDF â†’ ì´ë¯¸ì§€ ë³€í™˜
    image_parser = ImageOCRParser()
    images = image_parser.pdf_to_images(pdf_bytes, dpi=150)

    if not images:
        print("âŒ PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨")
        return {"success": False, "error": "ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨"}

    print(f"ğŸ“„ í˜ì´ì§€ ìˆ˜: {len(images)}")

    # VLM íŒŒì‹±
    vlm_parser = VLMParser()
    results = []

    for i, img_bytes in enumerate(images):
        print(f"  ì²˜ë¦¬ ì¤‘: Page {i+1}/{len(images)}...", end=" ", flush=True)
        result = vlm_parser.parse(img_bytes)
        results.append(result)

        if result.success:
            print(f"âœ“ ({result.elapsed_time:.2f}s)")
        else:
            print(f"âœ— ({result.error})")

    total_time = time.time() - start_time

    # ê²°ê³¼ í•©ì¹˜ê¸°
    combined_content = "\n\n".join(
        r.content for r in results if r.success and r.content
    )

    success_count = sum(1 for r in results if r.success)

    print(f"\nğŸ“Š ê²°ê³¼:")
    print(f"   - ì„±ê³µ: {success_count}/{len(results)} í˜ì´ì§€")
    print(f"   - ì´ ì‹œê°„: {total_time:.2f}s")
    print(f"   - í‰ê· : {total_time/len(images):.2f}s/page")
    print(f"   - ì¶”ì¶œ ê¸¸ì´: {len(combined_content)} chars")

    if verbose and combined_content:
        print(f"\nğŸ“ ì¶”ì¶œ ê²°ê³¼ (ì²˜ìŒ 500ì):")
        print("-" * 40)
        print(combined_content[:500])
        print("-" * 40)

    return {
        "success": success_count > 0,
        "content": combined_content,
        "elapsed_time": total_time,
        "page_count": len(images),
        "per_page_time": total_time / len(images)
    }


def test_ocr_text_parser(pdf_bytes: bytes, verbose: bool = False) -> dict:
    """OCR Parser (Text - pdfplumber) í…ŒìŠ¤íŠ¸"""
    from parsers.ocr_parser import OCRParser

    print("\n" + "=" * 60)
    print("ğŸ“– OCR Parser - Text (pdfplumber)")
    print("=" * 60)

    parser = OCRParser()

    # PDF íƒ€ì… í™•ì¸
    pdf_type = parser.detect_pdf_type(pdf_bytes)
    print(f"ğŸ“„ PDF íƒ€ì…: {pdf_type}")

    # íŒŒì‹±
    result = parser.parse_pdf(pdf_bytes)

    print(f"\nğŸ“Š ê²°ê³¼:")
    print(f"   - ì„±ê³µ: {'âœ“' if result.success else 'âœ—'}")
    print(f"   - í˜ì´ì§€ ìˆ˜: {result.page_count}")
    print(f"   - í…ìŠ¤íŠ¸ ì¡´ì¬: {'âœ“' if result.has_text else 'âœ—'}")
    print(f"   - í‘œ ê°œìˆ˜: {len(result.tables)}")
    print(f"   - ì´ ì‹œê°„: {result.elapsed_time:.2f}s")
    print(f"   - ì¶”ì¶œ ê¸¸ì´: {len(result.content)} chars")

    if verbose and result.content:
        print(f"\nğŸ“ ì¶”ì¶œ ê²°ê³¼ (ì²˜ìŒ 500ì):")
        print("-" * 40)
        print(result.content[:500])
        print("-" * 40)

    return {
        "success": result.success,
        "content": result.content,
        "elapsed_time": result.elapsed_time,
        "page_count": result.page_count,
        "has_text": result.has_text,
        "pdf_type": pdf_type
    }


def test_ocr_image_parser(pdf_bytes: bytes, verbose: bool = False) -> dict:
    """OCR Parser (Image - Docling) í…ŒìŠ¤íŠ¸"""
    from parsers.docling_parser import DoclingParser, check_docling_available

    print("\n" + "=" * 60)
    print("ğŸ” OCR Parser - Image (Docling + RapidOCR)")
    print("=" * 60)

    if not check_docling_available():
        print("âŒ Docling ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   pip install docling ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”.")
        return {"success": False, "error": "Docling not installed"}

    parser = DoclingParser(ocr_enabled=True)
    result = parser.parse_pdf(pdf_bytes)

    print(f"\nğŸ“Š ê²°ê³¼:")
    print(f"   - ì„±ê³µ: {'âœ“' if result.success else 'âœ—'}")
    print(f"   - í˜ì´ì§€ ìˆ˜: {result.page_count}")
    print(f"   - ì´ ì‹œê°„: {result.elapsed_time:.2f}s")
    print(f"   - ì¶”ì¶œ ê¸¸ì´ (text): {len(result.content)} chars")
    print(f"   - ì¶”ì¶œ ê¸¸ì´ (markdown): {len(result.markdown)} chars")

    if result.error:
        print(f"   - ì—ëŸ¬: {result.error}")

    if verbose and result.content:
        print(f"\nğŸ“ ì¶”ì¶œ ê²°ê³¼ (ì²˜ìŒ 500ì):")
        print("-" * 40)
        print(result.content[:500])
        print("-" * 40)

    return {
        "success": result.success,
        "content": result.content,
        "markdown": result.markdown,
        "elapsed_time": result.elapsed_time,
        "page_count": result.page_count,
        "error": result.error
    }


# =============================================================================
# Evaluation
# =============================================================================

def evaluate_results(results: dict, ground_truth: str, tokenizer=None, tokenizer_name: str = "whitespace") -> dict:
    """ê²°ê³¼ í‰ê°€ (CER, WER ê³„ì‚°) - jiwer ì‚¬ìš©

    Args:
        results: íŒŒì„œë³„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        ground_truth: Ground Truth í…ìŠ¤íŠ¸
        tokenizer: WER ê³„ì‚°ìš© í† í¬ë‚˜ì´ì € í•¨ìˆ˜
        tokenizer_name: í† í¬ë‚˜ì´ì € ì´ë¦„ (ì¶œë ¥ìš©)
    """
    print("\n" + "=" * 60)
    print(f"ğŸ“Š í‰ê°€ ê²°ê³¼ (Ground Truth ë¹„êµ) - jiwer")
    print(f"   WER Tokenizer: {tokenizer_name}")
    print("=" * 60)

    gt_normalized = normalize_text(ground_truth)
    print(f"Ground Truth ê¸¸ì´: {len(gt_normalized)} chars (ì •ê·œí™” í›„)")
    print()

    evaluation = {}

    for parser_name, result in results.items():
        if not result.get("success"):
            print(f"{parser_name}: SKIP (íŒŒì‹± ì‹¤íŒ¨)")
            evaluation[parser_name] = {"cer": None, "wer": None}
            continue

        content = result.get("content", "")
        if not content:
            print(f"{parser_name}: SKIP (ë‚´ìš© ì—†ìŒ)")
            evaluation[parser_name] = {"cer": None, "wer": None}
            continue

        # ì •ê·œí™”
        content_normalized = normalize_text(content)

        # CER, WER ê³„ì‚° (jiwer)
        cer_result = calculate_cer(content_normalized, gt_normalized)
        wer_result = calculate_wer(content_normalized, gt_normalized, tokenizer)

        cer = cer_result["cer"]
        wer = wer_result["wer"]

        print(f"{parser_name}:")
        print(f"   - CER: {cer:.4f} ({cer*100:.2f}%)")
        print(f"      â””â”€ S:{cer_result.get('substitutions', 0)} D:{cer_result.get('deletions', 0)} I:{cer_result.get('insertions', 0)}")
        print(f"   - WER: {wer:.4f} ({wer*100:.2f}%)")
        print(f"      â””â”€ S:{wer_result.get('substitutions', 0)} D:{wer_result.get('deletions', 0)} I:{wer_result.get('insertions', 0)}")
        print(f"      â””â”€ Tokens: ref={wer_result.get('ref_tokens', 0)} hyp={wer_result.get('hyp_tokens', 0)}")
        print(f"   - Latency: {result.get('elapsed_time', 0):.2f}s")
        print()

        evaluation[parser_name] = {
            "cer": cer,
            "cer_detail": cer_result,
            "wer": wer,
            "wer_detail": wer_result,
            "latency": result.get("elapsed_time", 0),
            "tokenizer": tokenizer_name
        }

    return evaluation


def save_results_to_files(results: dict, output_dir: str, pdf_name: str, evaluation: dict = None, tokenizer_name: str = "whitespace"):
    """íŒŒì‹± ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
    from pathlib import Path
    import json
    from datetime import datetime

    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    base_name = Path(pdf_name).stem

    print("\n" + "=" * 60)
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
    print("=" * 60)

    saved_files = []

    # 1. ê° íŒŒì„œë³„ ì¶œë ¥ ì €ì¥
    for parser_name, result in results.items():
        if not result.get("success"):
            continue

        content = result.get("content", "")
        if not content:
            continue

        safe_name = parser_name.lower().replace(" ", "-")
        ext = ".md" if "markdown" in result else ".txt"
        filename = f"{safe_name}_output{ext}"
        filepath = output_path / filename

        save_content = result.get("markdown", content)
        filepath.write_text(save_content, encoding="utf-8")
        saved_files.append(filepath)
        print(f"   âœ“ {filename} ({len(save_content)} chars)")

    # 2. í‰ê°€ ê²°ê³¼ JSON ì €ì¥
    meta = {
        "pdf": pdf_name,
        "timestamp": timestamp,
        "tokenizer": tokenizer_name,
        "results": {}
    }
    for name, result in results.items():
        meta["results"][name] = {
            "success": result.get("success"),
            "elapsed_time": result.get("elapsed_time"),
            "content_length": len(result.get("content", ""))
        }
        if evaluation and name in evaluation:
            eval_data = evaluation[name]
            meta["results"][name]["cer"] = eval_data.get("cer")
            meta["results"][name]["wer"] = eval_data.get("wer")

    meta_path = output_path / "evaluation.json"
    meta_path.write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding="utf-8")
    print(f"   âœ“ evaluation.json")

    # 3. ìš”ì•½ ë§ˆí¬ë‹¤ìš´ ì €ì¥
    summary_lines = [
        f"# Parsing Test Results",
        f"",
        f"- **Date**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"- **PDF**: {pdf_name}",
        f"- **Tokenizer**: {tokenizer_name}",
        f"",
        f"## Results",
        f"",
        f"| Parser | Success | Latency | Length |",
        f"|--------|---------|---------|--------|",
    ]

    for name, result in results.items():
        success = "âœ“" if result.get("success") else "âœ—"
        latency = f"{result.get('elapsed_time', 0):.2f}s"
        length = f"{len(result.get('content', ''))} chars"
        summary_lines.append(f"| {name} | {success} | {latency} | {length} |")

    if evaluation:
        summary_lines.extend([
            f"",
            f"## Evaluation (vs Ground Truth)",
            f"",
            f"| Parser | CER | WER |",
            f"|--------|-----|-----|",
        ])
        for name, eval_data in evaluation.items():
            cer = eval_data.get("cer")
            wer = eval_data.get("wer")
            cer_str = f"{cer*100:.2f}%" if cer is not None else "N/A"
            wer_str = f"{wer*100:.2f}%" if wer is not None else "N/A"
            summary_lines.append(f"| {name} | {cer_str} | {wer_str} |")

    summary_path = output_path / "README.md"
    summary_path.write_text("\n".join(summary_lines), encoding="utf-8")
    print(f"   âœ“ README.md (ìš”ì•½)")

    return saved_files


def print_summary(results: dict, evaluation: dict = None):
    """ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
    print("\n" + "=" * 60)
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ìš”ì•½")
    print("=" * 60)

    print("\n| Parser | ì„±ê³µ | ì‹œê°„ | ì¶”ì¶œ ê¸¸ì´ |")
    print("|--------|------|------|----------|")

    for name, result in results.items():
        success = "âœ“" if result.get("success") else "âœ—"
        time_str = f"{result.get('elapsed_time', 0):.2f}s"
        length = len(result.get("content", ""))
        print(f"| {name} | {success} | {time_str} | {length} chars |")

    if evaluation:
        print("\n| Parser | CER | WER | Latency |")
        print("|--------|-----|-----|---------|")

        for name, eval_result in evaluation.items():
            cer = eval_result.get("cer")
            wer = eval_result.get("wer")
            latency = eval_result.get("latency", 0)

            cer_str = f"{cer*100:.2f}%" if cer is not None else "N/A"
            wer_str = f"{wer*100:.2f}%" if wer is not None else "N/A"

            print(f"| {name} | {cer_str} | {wer_str} | {latency:.2f}s |")


# =============================================================================
# Main
# =============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="3ê°œ Parser ë¹„êµ í…ŒìŠ¤íŠ¸ (VLM, OCR-Text, OCR-Image)"
    )
    parser.add_argument(
        "--pdf", "-p",
        required=True,
        help="í…ŒìŠ¤íŠ¸í•  PDF íŒŒì¼ ê²½ë¡œ"
    )
    parser.add_argument(
        "--gt", "-g",
        help="Ground Truth íŒŒì¼ ê²½ë¡œ (ì„ íƒ)"
    )
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="ìƒì„¸ ì¶œë ¥ (ì¶”ì¶œ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°)"
    )
    parser.add_argument(
        "--skip-vlm",
        action="store_true",
        help="VLM Parser í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ"
    )
    parser.add_argument(
        "--skip-docling",
        action="store_true",
        help="Docling Parser í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ"
    )
    parser.add_argument(
        "--output-dir", "-o",
        help="íŒŒì‹± ê²°ê³¼ë¥¼ ì €ì¥í•  ë””ë ‰í† ë¦¬"
    )
    parser.add_argument(
        "--save-docs",
        action="store_true",
        help="ê²°ê³¼ë¥¼ docs/Parsing_test_<ì¼ì>/ í´ë”ì— ì €ì¥"
    )
    parser.add_argument(
        "--tokenizer", "-t",
        choices=["whitespace", "mecab", "okt"],
        default="whitespace",
        help="WER ê³„ì‚°ìš© í† í¬ë‚˜ì´ì € (ê¸°ë³¸: whitespace, í•œêµ­ì–´: mecab ë˜ëŠ” okt)"
    )

    args = parser.parse_args()

    # --save-docs ì˜µì…˜ ì²˜ë¦¬
    if args.save_docs:
        from datetime import datetime
        date_str = datetime.now().strftime("%Y%m%d")
        args.output_dir = f"docs/Parsing_test_{date_str}"

    # PDF íŒŒì¼ ì½ê¸°
    pdf_path = Path(args.pdf)
    if not pdf_path.exists():
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        sys.exit(1)

    print("=" * 60)
    print("ğŸ”¬ VLM Document Parsing Quality Test")
    print("=" * 60)
    print(f"ğŸ“„ PDF: {pdf_path}")

    pdf_bytes = pdf_path.read_bytes()
    print(f"ğŸ“¦ í¬ê¸°: {len(pdf_bytes) / 1024:.1f} KB")

    # Ground Truth ì½ê¸° (ì„ íƒ)
    ground_truth = None
    if args.gt:
        gt_path = Path(args.gt)
        if gt_path.exists():
            ground_truth = gt_path.read_text(encoding="utf-8")
            print(f"ğŸ“‹ Ground Truth: {gt_path} ({len(ground_truth)} chars)")
        else:
            print(f"âš ï¸ Ground Truth íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {gt_path}")

    results = {}

    # 1. VLM Parser
    if not args.skip_vlm:
        try:
            results["VLM"] = test_vlm_parser(pdf_bytes, args.verbose)
        except Exception as e:
            print(f"âŒ VLM Parser ì˜¤ë¥˜: {e}")
            results["VLM"] = {"success": False, "error": str(e)}

    # 2. OCR Parser (Text)
    try:
        results["OCR-Text"] = test_ocr_text_parser(pdf_bytes, args.verbose)
    except Exception as e:
        print(f"âŒ OCR-Text Parser ì˜¤ë¥˜: {e}")
        results["OCR-Text"] = {"success": False, "error": str(e)}

    # 3. OCR Parser (Image - Docling)
    if not args.skip_docling:
        try:
            results["OCR-Image"] = test_ocr_image_parser(pdf_bytes, args.verbose)
        except Exception as e:
            print(f"âŒ OCR-Image Parser ì˜¤ë¥˜: {e}")
            results["OCR-Image"] = {"success": False, "error": str(e)}

    # í‰ê°€ (Ground Truthê°€ ìˆëŠ” ê²½ìš°)
    evaluation = None
    if ground_truth:
        tokenizer = get_tokenizer(args.tokenizer)
        evaluation = evaluate_results(results, ground_truth, tokenizer, args.tokenizer)

    # ê²°ê³¼ íŒŒì¼ ì €ì¥ (--output-dir ë˜ëŠ” --save-docs ì˜µì…˜)
    if args.output_dir:
        save_results_to_files(results, args.output_dir, args.pdf, evaluation, args.tokenizer)

    # ìš”ì•½ ì¶œë ¥
    print_summary(results, evaluation)


if __name__ == "__main__":
    main()
