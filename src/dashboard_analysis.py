"""
VLM Document Parsing Quality Analysis Dashboard

CLI í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ì—¬ Tech Report ì‘ì„±ì„ ì§€ì›í•˜ëŠ” ì •ì  ëŒ€ì‹œë³´ë“œ

Features:
- JSON ê²°ê³¼ íŒŒì¼ ë¡œë“œ (results/parsing_results.json)
- @st.cache_data ìºì‹± (1ì‹œê°„ TTL)
- í˜ì´ì§€ë„¤ì´ì…˜ (10ê°œ í…ŒìŠ¤íŠ¸ ì´ˆê³¼ ì‹œ)
- ì°¨íŠ¸ PNG ë‹¤ìš´ë¡œë“œ
- CSV ë‚´ë³´ë‚´ê¸°

Usage:
    streamlit run src/dashboard_analysis.py
"""

import sys
from pathlib import Path

_src_dir = Path(__file__).parent
if str(_src_dir) not in sys.path:
    sys.path.insert(0, str(_src_dir))

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from typing import Dict, List, Any
import numpy as np

from dashboard.data_loader import (
    load_all_results_cached,
    get_test_ids,
    get_parser_names,
    get_parsing_summary_df,
    get_chunking_summary_df,
    get_aggregated_parser_df,
    get_test_evaluation,
    get_test_chunking,
    get_chunking_for_test,
    get_tests_with_chunking,
    get_chart_download_config,
    export_df_to_csv,
    # Backward compatibility
    get_parsing_data,
    get_chunking_data,
    paginate_data,
    get_chunking_parsers,
    get_chunking_data_for_parser,
)
from dashboard.charts import (
    STRATEGY_COLORS,
    create_parser_chunking_comparison,
    create_bc_document_flow,
    create_cs_mean_std_bar,
)
from dashboard.styles import PARSER_COLORS as STYLE_PARSER_COLORS

# =============================================================================
# í˜ì´ì§€ ì„¤ì •
# =============================================================================

st.set_page_config(
    page_title="VLM Document Parsing Quality Analysis",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# =============================================================================
# ìŠ¤íƒ€ì¼ ì„¤ì •
# =============================================================================

st.markdown("""
<style>
    /* Sidebar ì™„ì „ ìˆ¨ê¹€ */
    [data-testid="stSidebar"] { display: none; }
    [data-testid="stSidebarCollapsedControl"] { display: none; }

    /* ì „ì²´ ë°°ê²½ */
    .stApp { background-color: #FAFAFA; }

    /* í—¤ë” */
    h1, h2, h3 { color: #1a1a2e !important; font-weight: 600 !important; }

    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    [data-testid="stMetric"] {
        background-color: #FFFFFF;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #E5E5E5;
    }
    [data-testid="stMetricValue"] { color: #1a1a2e !important; font-size: 1.5rem !important; }
    [data-testid="stMetricLabel"] { color: #666666 !important; }

    /* íƒ­ */
    .stTabs [data-baseweb="tab-list"] { gap: 8px; border-bottom: 1px solid #E5E5E5; }
    .stTabs [data-baseweb="tab"] {
        color: #666666;
        font-weight: 500;
        padding: 0.75rem 1.5rem;
    }
    .stTabs [aria-selected="true"] {
        color: #1a1a2e !important;
        border-bottom: 2px solid #4F46E5 !important;
    }

    /* í…Œì´ë¸” */
    .stDataFrame { border-radius: 8px; }

    /* êµ¬ë¶„ì„  */
    hr { border-color: #E5E5E5; margin: 2rem 0; }

    /* ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ */
    .download-btn {
        background-color: #F3F4F6;
        border: 1px solid #E5E5E5;
        border-radius: 6px;
        padding: 0.5rem 1rem;
        font-size: 0.875rem;
        cursor: pointer;
    }
</style>
""", unsafe_allow_html=True)

# =============================================================================
# ìƒìˆ˜
# =============================================================================

VERSION = "v0.4.0"  # Added parser-specific chunking analysis (MoC-based)
PAGE_SIZE = 10  # í˜ì´ì§€ë„¤ì´ì…˜ í¬ê¸°

# ë™ì  ìƒ‰ìƒ ìƒì„±ìš© ê¸°ë³¸ íŒ”ë ˆíŠ¸ (íŒŒì„œ ì¶”ê°€ ì‹œ ìë™ í™•ì¥)
DEFAULT_COLORS = [
    "#4F46E5",  # VLM - ì¸ë””ê³ 
    "#059669",  # OCR-Text - ì—ë©”ë„ë“œ
    "#D97706",  # OCR-Image - ì•°ë²„
    "#7C3AED",  # TwoStage-Text - ë³´ë¼
    "#0891B2",  # TwoStage-Image - ì²­ë¡
    "#DC2626",  # ì—¬ìœ  - ë ˆë“œ
    "#EC4899",  # ì—¬ìœ  - í•‘í¬
]


def get_parser_colors(parsers: List[str]) -> Dict[str, str]:
    """íŒŒì„œë³„ ìƒ‰ìƒ ë™ì  ìƒì„± (styles.pyì˜ PARSER_COLORSë¥¼ ë‹¨ì¼ ì§„ì‹¤ ê³µê¸‰ì›ìœ¼ë¡œ ì‚¬ìš©)"""
    colors = {}
    for i, parser in enumerate(parsers):
        # styles.pyì—ì„œ ì •ì˜ëœ ìƒ‰ìƒ ì‚¬ìš©, ì—†ìœ¼ë©´ ìˆœí™˜ ìƒ‰ìƒ
        colors[parser] = STYLE_PARSER_COLORS.get(parser, DEFAULT_COLORS[i % len(DEFAULT_COLORS)])
    return colors


# =============================================================================
# ë°ì´í„° ë¡œë“œ
# =============================================================================

@st.cache_data(ttl=300)
def load_data():
    """Load data with caching - scans results/test_*/ folders"""
    data = load_all_results_cached()
    if "error" in data:
        return data, True
    return data, False


# ë°ì´í„° ë¡œë“œ
raw_data, is_error = load_data()

# íŒŒì„œ ìƒ‰ìƒ
PARSER_NAMES = get_parser_names(raw_data)
PARSER_COLORS = get_parser_colors(PARSER_NAMES)

# ë³€í™˜ëœ ë°ì´í„° (í˜¸í™˜ì„± ìœ ì§€)
PARSING_DATA = get_parsing_data(raw_data)
CHUNKING_DATA = get_chunking_data(raw_data)

# ìƒˆë¡œìš´ í˜•ì‹ ë°ì´í„°
TEST_IDS = get_test_ids(raw_data)


# =============================================================================
# ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
# =============================================================================

def hex_to_rgba(hex_color: str, alpha: float = 0.1) -> str:
    """Hex ìƒ‰ìƒì„ rgbaë¡œ ë³€í™˜"""
    hex_color = hex_color.lstrip('#')
    r = int(hex_color[0:2], 16)
    g = int(hex_color[2:4], 16)
    b = int(hex_color[4:6], 16)
    return f"rgba({r},{g},{b},{alpha})"


def create_thin_bar_chart(data: Dict, metric: str, title: str,
                          lower_is_better: bool = False) -> go.Figure:
    """ì–‡ì€ ê°€ë¡œí˜• Bar Chart"""
    parsers = list(data["parsers"].keys())
    values = [data["parsers"][p].get(metric) or 0 for p in parsers]  # Handle None
    colors = [PARSER_COLORS.get(p, "#888") for p in parsers]

    fig = go.Figure()
    # Format based on metric type
    if metric == "elapsed_time":
        text_values = [f"{v:.1f}s" for v in values]
    else:
        text_values = [f"{v:.3f}" for v in values]

    fig.add_trace(go.Bar(
        y=parsers,
        x=values,
        orientation='h',
        marker_color=colors,
        marker_line_width=0,
        text=text_values,
        textposition="outside",
        textfont=dict(size=12, color="#333"),
    ))

    direction = "â† Lower is better" if lower_is_better else "Higher is better â†’"
    fig.update_layout(
        title=dict(text=title, font=dict(size=14, color="#1a1a2e"), x=0),
        height=180,
        margin=dict(l=10, r=80, t=40, b=25),
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        font=dict(size=12, color="#666"),
        xaxis=dict(showgrid=False, showticklabels=False, zeroline=False),
        yaxis=dict(showgrid=False, tickfont=dict(size=12)),
        showlegend=False,
        annotations=[dict(
            text=direction, x=1, y=-0.12, xref="paper", yref="paper",
            showarrow=False, font=dict(size=10, color="#888"), xanchor="right"
        )]
    )
    return fig


def create_radar_chart(all_data: Dict) -> go.Figure:
    """íŒŒì„œë³„ ì„±ëŠ¥ Radar Chart"""
    metrics = ["WER", "CER", "Struct-F1", "Latency"]
    fig = go.Figure()

    for parser in PARSER_NAMES:
        values = []
        for metric_key in ["wer", "cer", "structure_f1", "elapsed_time"]:
            vals = [
                test["parsers"][parser].get(metric_key, 0)
                for test in all_data.values()
                if parser in test["parsers"]
            ]
            # Filter out None values
            vals = [v for v in vals if v is not None]
            avg = np.mean(vals) if vals else 0

            # ì •ê·œí™” (ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ ê²ƒì€ ë°˜ì „, 0=worst, 1=best)
            if metric_key in ["wer", "cer"]:
                # WER/CER: 0% = 1.0 (best), 200%+ = 0.0 (worst)
                normalized = max(0, 1 - avg / 2)
            elif metric_key == "elapsed_time":
                # Latency: 0s = 1.0 (best), 120s+ = 0.0 (worst)
                normalized = max(0, 1 - avg / 120)
            elif metric_key == "structure_f1":
                # Structure F1: 0 = 0.0 (worst), 1 = 1.0 (best)
                normalized = avg
            else:
                normalized = avg
            values.append(normalized)

        values.append(values[0])  # ë‹«ê¸°

        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=metrics + [metrics[0]],
            name=parser,
            line=dict(color=PARSER_COLORS.get(parser, "#888"), width=3),
            fill='toself',
            fillcolor=hex_to_rgba(PARSER_COLORS.get(parser, "#888"), 0.1),
        ))

    fig.update_layout(
        polar=dict(
            radialaxis=dict(visible=True, range=[0, 1], showticklabels=False, gridcolor="#E5E5E5"),
            angularaxis=dict(tickfont=dict(size=13, color="#333"), gridcolor="#E5E5E5"),
            bgcolor="rgba(0,0,0,0)",
        ),
        showlegend=True,
        legend=dict(orientation="h", yanchor="bottom", y=-0.15, xanchor="center", x=0.5, font=dict(size=12)),
        height=450,
        margin=dict(l=80, r=80, t=40, b=80),
        paper_bgcolor="rgba(0,0,0,0)",
    )
    return fig


def create_bc_cs_scatter(chunking_data: Dict) -> go.Figure:
    """BC vs CS Scatter Plot"""
    fig = go.Figure()

    for strategy, data in chunking_data.items():
        bc_values = [c.get("bc", 0) for c in data.get("chunks", [])]
        cs_values = [c.get("cs", 0) for c in data.get("chunks", [])]

        if not bc_values:
            continue

        fig.add_trace(go.Scatter(
            x=bc_values, y=cs_values, mode='markers', name=strategy,
            marker=dict(
                size=12,
                color=STRATEGY_COLORS.get(strategy, "#888"),
                line=dict(width=1, color="white"),
                opacity=0.8,
            ),
            hovertemplate=f"<b>{strategy}</b><br>BC: %{{x:.2f}}<br>CS: %{{y:.2f}}<extra></extra>",
        ))

    # Quadrant ì˜ì—­
    fig.add_shape(type="rect", x0=0.5, x1=1, y0=0, y1=0.5,
                  fillcolor="rgba(16, 185, 129, 0.05)", line_width=0)
    fig.add_shape(type="rect", x0=0, x1=0.5, y0=0.5, y1=1,
                  fillcolor="rgba(239, 68, 68, 0.05)", line_width=0)

    fig.add_hline(y=0.5, line_dash="dot", line_color="#ccc", line_width=1)
    fig.add_vline(x=0.5, line_dash="dot", line_color="#ccc", line_width=1)

    annotations = [
        dict(x=0.75, y=0.25, text="ì´ìƒì <br>(BCâ†‘ CSâ†“)", showarrow=False,
             font=dict(size=9, color="#059669"), opacity=0.7),
        dict(x=0.25, y=0.75, text="Over-merge<br>(BCâ†“ CSâ†‘)", showarrow=False,
             font=dict(size=9, color="#DC2626"), opacity=0.7),
        dict(x=0.75, y=0.75, text="Fragmentation<br>(BCâ†‘ CSâ†‘)", showarrow=False,
             font=dict(size=9, color="#D97706"), opacity=0.7),
        dict(x=0.25, y=0.25, text="Structural<br>Failure", showarrow=False,
             font=dict(size=9, color="#6B7280"), opacity=0.7),
    ]

    fig.update_layout(
        title=dict(text="BCâ€“CS Distribution by Strategy", font=dict(size=14, color="#1a1a2e"), x=0),
        xaxis=dict(title="Boundary Clarity (BC) â†’", range=[0, 1], gridcolor="#E5E5E5", zeroline=False),
        yaxis=dict(title="Chunk Stickiness (CS) â†“", range=[0, 1], gridcolor="#E5E5E5", zeroline=False),
        height=450, margin=dict(l=60, r=30, t=50, b=50),
        paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0, font=dict(size=10)),
        annotations=annotations,
    )
    return fig


def create_grouped_bar(all_data: Dict, metric: str, title: str, lower_is_better: bool = False) -> go.Figure:
    """ì „ì²´ í…ŒìŠ¤íŠ¸ ë¹„êµ Grouped Bar Chart"""
    test_ids = [d["id"] for d in all_data.values()]
    fig = go.Figure()

    for parser in PARSER_NAMES:
        color = PARSER_COLORS.get(parser, "#888")
        values = [test["parsers"].get(parser, {}).get(metric) or 0 for test in all_data.values()]  # Handle None
        fig.add_trace(go.Bar(
            name=parser, x=test_ids, y=values,
            marker_color=color, marker_line_width=0,
            text=[f"{v:.2f}" if metric != "elapsed_time" else f"{v:.1f}s" for v in values],
            textposition="outside", textfont=dict(size=11), width=0.3,
        ))

    direction = "â†“ Lower is better" if lower_is_better else "â†‘ Higher is better"
    fig.update_layout(
        title=dict(text=f"{title} ({direction})", font=dict(size=15, color="#1a1a2e"), x=0),
        barmode="group", height=380,
        margin=dict(l=50, r=30, t=60, b=80),
        paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
        font=dict(size=12, color="#666"),
        xaxis=dict(showgrid=False, tickfont=dict(size=12)),
        yaxis=dict(gridcolor="#E5E5E5", gridwidth=0.5, zeroline=False, tickfont=dict(size=11)),
        legend=dict(orientation="h", yanchor="top", y=-0.12, xanchor="center", x=0.5, font=dict(size=11)),
        bargap=0.25, bargroupgap=0.1,
    )
    return fig


def create_metrics_comparison_subplot(all_data: Dict) -> go.Figure:
    """4ê°œ ë©”íŠ¸ë¦­ì„ í•˜ë‚˜ì˜ Subplotìœ¼ë¡œ í†µí•©í•œ ì°¨íŠ¸

    ì¥ì :
    - Legendê°€ í•œ ë²ˆë§Œ í‘œì‹œë¨ (ì¤‘ë³µ ì œê±°)
    - ì¼ê´€ëœ ë ˆì´ì•„ì›ƒ
    - í…ŒìŠ¤íŠ¸ ê°„ ë¹„êµê°€ ìš©ì´
    """
    test_ids = [d["id"] for d in all_data.values()]

    # ë©”íŠ¸ë¦­ ì •ì˜: (key, title, lower_is_better, format_func)
    metrics = [
        ("wer", "WER â†“", True, lambda v: f"{v:.2f}"),
        ("cer", "CER â†“", True, lambda v: f"{v:.2f}"),
        ("structure_f1", "Structure F1 â†‘", False, lambda v: f"{v:.2f}"),
        ("elapsed_time", "Latency â†“", True, lambda v: f"{v:.1f}s"),
    ]

    # 2x2 ì„œë¸Œí”Œë¡¯ ìƒì„± (ìƒí•˜ ê°„ê²© ë„“ê²Œ)
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=[m[1] for m in metrics],
        horizontal_spacing=0.10,
        vertical_spacing=0.18,
    )

    # ê° ë©”íŠ¸ë¦­ë³„ë¡œ ë°” ì¶”ê°€
    for idx, (metric_key, title, lower_is_better, fmt) in enumerate(metrics):
        row = idx // 2 + 1
        col = idx % 2 + 1

        for parser_idx, parser in enumerate(PARSER_NAMES):
            color = PARSER_COLORS.get(parser, "#888")
            values = [
                test["parsers"].get(parser, {}).get(metric_key) or 0
                for test in all_data.values()
            ]

            # ì²« ë²ˆì§¸ ì„œë¸Œí”Œë¡¯ì—ì„œë§Œ legend í‘œì‹œ
            show_legend = (idx == 0)

            fig.add_trace(
                go.Bar(
                    name=parser,
                    x=test_ids,
                    y=values,
                    marker_color=color,
                    marker_line_width=0,
                    text=[fmt(v) for v in values],
                    textposition="outside",
                    textfont=dict(size=10),
                    showlegend=show_legend,
                    legendgroup=parser,  # legend ê·¸ë£¹í•‘
                ),
                row=row, col=col
            )

    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        height=650,
        barmode="group",
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        font=dict(size=11, color="#666"),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.04,
            xanchor="left",
            x=0,
            font=dict(size=14),
        ),
        margin=dict(l=50, r=30, t=100, b=40),
        bargap=0.15,
        bargroupgap=0.05,
    )

    # ê° ì¶• ì„¤ì •
    for i in range(1, 5):
        fig.update_xaxes(showgrid=False, tickfont=dict(size=10), row=(i-1)//2+1, col=(i-1)%2+1)
        fig.update_yaxes(gridcolor="#E5E5E5", gridwidth=0.5, zeroline=False, tickfont=dict(size=10), row=(i-1)//2+1, col=(i-1)%2+1)

    # ì„œë¸Œí”Œë¡¯ íƒ€ì´í‹€ ìŠ¤íƒ€ì¼ (í¬ê²Œ, ì¢Œì¸¡ ì •ë ¬)
    for annotation in fig['layout']['annotations']:
        annotation['font'] = dict(size=15, color="#1a1a2e", weight="bold")
        annotation['xanchor'] = 'left'
        # ì¢Œì¸¡ ì •ë ¬ì„ ìœ„í•´ x ìœ„ì¹˜ ì¡°ì • (ê° ì„œë¸Œí”Œë¡¯ì˜ ì‹œì‘ì )
        if annotation['x'] < 0.5:
            annotation['x'] = 0.0
        else:
            annotation['x'] = 0.55

    return fig


# =============================================================================
# ë©”ì¸ ëŒ€ì‹œë³´ë“œ
# =============================================================================

# í—¤ë”
st.title("ğŸ“„ VLM Document Parsing Quality Analysis")
st.caption(f"CLI í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™” | Tech Report ì‘ì„± ì§€ì› | {VERSION}")

# ì—ëŸ¬ ê²½ê³ 
if is_error:
    st.error(f"âš ï¸ {raw_data.get('error', 'í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')}")
    st.info("í…ŒìŠ¤íŠ¸ ì‹¤í–‰: `python -m src.eval_parsers --all`")
    st.stop()

# ë°ì´í„° ì •ë³´
data_info_cols = st.columns([1, 1, 1, 2])
with data_info_cols[0]:
    st.metric("Total Tests", raw_data.get("test_count", len(PARSING_DATA)))
with data_info_cols[1]:
    st.metric("Parsers", len(PARSER_NAMES))
with data_info_cols[2]:
    chunking_tests = len(get_tests_with_chunking(raw_data))
    st.metric("Chunking Tests", chunking_tests)
with data_info_cols[3]:
    loaded_at = raw_data.get("loaded_at", "N/A")
    st.caption(f"Data Version: {raw_data.get('version', 'N/A')} | Loaded: {loaded_at}")

st.markdown("---")

# íƒ­ êµ¬ì„±
tab_parsing, tab_chunking, tab_result = st.tabs([
    "ğŸ” Parsing Test",
    "ğŸ“¦ Chunking Test",
    "ğŸ“Š ì¢…í•© ë¶„ì„"
])


# =============================================================================
# TAB 1: Parsing Test
# =============================================================================

with tab_parsing:
    st.markdown("## Parsing Test Results")

    # Metrics ì •ì˜
    with st.expander("ğŸ“ Metrics ì •ì˜", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**WER (Word Error Rate)** Â· :green[â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("ë‹¨ì–´ ë‹¨ìœ„ ì˜¤ë¥˜ìœ¨. ì‚½ì…/ì‚­ì œ/ëŒ€ì²´ ì˜¤ë¥˜ ì¢…í•©.")
            st.markdown("**CER (Character Error Rate)** Â· :green[â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("ë¬¸ì ë‹¨ìœ„ ì˜¤ë¥˜ìœ¨. ëˆ„ë½/ì¶”ê°€/ë³€ê²½ ë¬¸ì ì¶”ì .")
        with col2:
            st.markdown("**Structure F1** Â· :orange[â†‘ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("ë§ˆí¬ë‹¤ìš´ êµ¬ì¡° ìš”ì†Œ(í—¤ë”©, ë¦¬ìŠ¤íŠ¸, í…Œì´ë¸”) ê²€ì¶œ F1 ìŠ¤ì½”ì–´.")
            st.markdown("**Latency** Â· :green[â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("ë¬¸ì„œ 1ê±´ Parsing ì²˜ë¦¬ ì‹œê°„ (ì´ˆ).")

    st.markdown("---")

    # Global Performance Summary
    st.markdown("### ğŸ“ˆ Global Performance Summary")

    col_table, col_radar = st.columns([1, 1])

    with col_table:
        # DataFrame ìƒì„±
        summary_df = get_parsing_summary_df(raw_data)
        # Use available columns from new format (including Structure F1)
        display_df = summary_df[["Test ID", "Parser", "CER %", "WER %", "Struct-F1 %", "Latency (s)", "Success"]].copy()
        display_df = display_df.rename(columns={
            "Test ID": "Test",
            "Struct-F1 %": "Struct-F1",
            "Latency (s)": "Latency",
        })
        display_df["Latency"] = display_df["Latency"].apply(lambda x: f"{x:.1f}s")

        st.dataframe(display_df, use_container_width=True, hide_index=True, height=350)

        # CSV ë‹¤ìš´ë¡œë“œ
        csv_data = export_df_to_csv(summary_df)
        st.download_button(
            label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_data,
            file_name="parsing_summary.csv",
            mime="text/csv",
        )

    with col_radar:
        radar_fig = create_radar_chart(PARSING_DATA)
        st.plotly_chart(
            radar_fig,
            use_container_width=True,
            config=get_chart_download_config("radar_chart")
        )

    # Metrics Comparison - í†µí•© Subplot ì°¨íŠ¸
    st.markdown("#### Metrics Comparison")

    metrics_fig = create_metrics_comparison_subplot(PARSING_DATA)
    st.plotly_chart(
        metrics_fig,
        use_container_width=True,
        config=get_chart_download_config("metrics_comparison")
    )

    st.markdown("---")

    # Detailed Test Analysis with Pagination
    st.markdown("### ğŸ”¬ Detailed Test Analysis")

    # í˜ì´ì§€ë„¤ì´ì…˜ (10ê°œ ì´ˆê³¼ ì‹œ)
    test_items = list(PARSING_DATA.items())
    total_tests = len(test_items)

    if total_tests > PAGE_SIZE:
        # í˜ì´ì§€ ì„ íƒ
        col_page_info, col_page_nav = st.columns([2, 1])

        with col_page_info:
            st.caption(f"ì´ {total_tests}ê°œ í…ŒìŠ¤íŠ¸ (í˜ì´ì§€ë‹¹ {PAGE_SIZE}ê°œ)")

        # í˜ì´ì§€ ìƒíƒœ
        if "parsing_page" not in st.session_state:
            st.session_state.parsing_page = 1

        total_pages = (total_tests + PAGE_SIZE - 1) // PAGE_SIZE

        with col_page_nav:
            page = st.number_input(
                "Page",
                min_value=1,
                max_value=total_pages,
                value=st.session_state.parsing_page,
                key="parsing_page_input"
            )
            st.session_state.parsing_page = page

        # í˜„ì¬ í˜ì´ì§€ ë°ì´í„°
        paginated_items, _, _, _ = paginate_data(test_items, page, PAGE_SIZE)
    else:
        paginated_items = test_items

    # í…ŒìŠ¤íŠ¸ë³„ ìƒì„¸ (Lazy Loading via Expander)
    for test_id, test_data in paginated_items:
        # ë©”íƒ€ë°ì´í„°ì—ì„œ ì •ë³´ ì¶”ì¶œ (ìë™ ì¶”ì¶œ í˜•ì‹)
        metadata = test_data.get("metadata", {})
        title = metadata.get("title", test_data.get('id', test_id))
        filename = metadata.get("filename", test_data.get('name', ''))
        doc_type = metadata.get("doc_type", test_data.get('doc_type', 'unknown'))
        pages = metadata.get("pages", test_data.get('pages', 0))
        file_size_kb = metadata.get("file_size_kb", test_data.get('file_size_kb', 0))
        language = metadata.get("language", test_data.get('language', ''))
        has_text_layer = metadata.get("has_text_layer", test_data.get('has_text_layer', False))

        # test_idì—ì„œ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: test_1 â†’ 1)
        test_num = test_id.replace("test_", "").replace("_", " ").title()

        # Expander ì œëª©: "ğŸ“„ Test 1: filename.pdf (PDF, 5p)"
        page_info = f", {pages}p" if pages else ""
        expander_title = f"ğŸ“„ **Test {test_num}**: {filename} ({doc_type}{page_info})"

        with st.expander(expander_title, expanded=False):
            # íŒŒì¼ ì •ë³´ í‘œì‹œ
            info_cols = st.columns([2, 1, 1, 1])
            with info_cols[0]:
                st.caption(f"ğŸ“ {title}")
            with info_cols[1]:
                if file_size_kb:
                    size_str = f"{file_size_kb:.0f}KB" if file_size_kb < 1024 else f"{file_size_kb/1024:.1f}MB"
                    st.caption(f"ğŸ’¾ {size_str}")
            with info_cols[2]:
                if language:
                    st.caption(f"ğŸŒ {language.upper()}")
            with info_cols[3]:
                text_layer_icon = "âœ…" if has_text_layer else "âŒ"
                st.caption(f"ğŸ“ Text: {text_layer_icon}")
            st.divider()

            # í…Œì´ë¸”
            detail_rows = []
            for parser, metrics in test_data["parsers"].items():
                structure_f1 = metrics.get('structure_f1')
                struct_f1_display = f"{structure_f1:.3f}" if structure_f1 is not None else "N/A"

                detail_rows.append({
                    "Parser": parser,
                    "WER â†“": f"{metrics.get('wer') or 0:.3f}",
                    "CER â†“": f"{metrics.get('cer') or 0:.3f}",
                    "Struct-F1 â†‘": struct_f1_display,
                    "Latency â†“": f"{metrics.get('elapsed_time') or 0:.1f}s",
                })
            st.dataframe(pd.DataFrame(detail_rows), use_container_width=True, hide_index=True)

            # Bar Charts
            chart_cols = st.columns(2)
            with chart_cols[0]:
                st.plotly_chart(
                    create_thin_bar_chart(test_data, "wer", "WER", lower_is_better=True),
                    use_container_width=True,
                    config=get_chart_download_config(f"{test_id}_wer")
                )
                st.plotly_chart(
                    create_thin_bar_chart(test_data, "cer", "CER", lower_is_better=True),
                    use_container_width=True,
                    config=get_chart_download_config(f"{test_id}_cer")
                )
            with chart_cols[1]:
                st.plotly_chart(
                    create_thin_bar_chart(test_data, "structure_f1", "Structure F1", lower_is_better=False),
                    use_container_width=True,
                    config=get_chart_download_config(f"{test_id}_structure_f1")
                )
                st.plotly_chart(
                    create_thin_bar_chart(test_data, "elapsed_time", "Latency", lower_is_better=True),
                    use_container_width=True,
                    config=get_chart_download_config(f"{test_id}_latency")
                )


# =============================================================================
# TAB 2: Chunking Test
# =============================================================================

def get_chunking_data_dict(raw_data: Dict) -> Dict:
    """Chunking ë°ì´í„°ë¥¼ Parsingê³¼ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    chunking_dict = {}
    for test_id, test_data in raw_data.get("tests", {}).items():
        chunking = test_data.get("chunking", {})
        if not chunking or not chunking.get("results"):
            continue

        # Parsingê³¼ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        parsers_data = {}
        for parser, result in chunking.get("results", {}).items():
            bc = result.get("bc", {})
            cs = result.get("cs", {})
            parsers_data[parser] = {
                "bc": bc.get("score"),
                "bc_min": bc.get("min"),
                "bc_max": bc.get("max"),
                "bc_std": bc.get("std"),
                "cs": cs.get("score"),
                "chunk_count": result.get("chunk_count", 0),
            }

        if parsers_data:
            chunking_dict[test_id] = {
                "id": test_id,
                "parsers": parsers_data,
                "config": chunking.get("config", {}),
                "metadata": test_data.get("evaluation", {}).get("metadata", {}),
            }

    return chunking_dict


def create_chunking_metrics_subplot(chunking_data: Dict) -> go.Figure:
    """BC/CS ë©”íŠ¸ë¦­ì„ í•˜ë‚˜ì˜ Subplotìœ¼ë¡œ í†µí•©í•œ ì°¨íŠ¸ (Parsingê³¼ ë™ì¼í•œ í˜•ì‹)"""
    test_ids = [d["id"] for d in chunking_data.values()]

    # ë©”íŠ¸ë¦­ ì •ì˜: (key, title, lower_is_better, format_func)
    metrics = [
        ("bc", "BC (Boundary Clarity) â†‘", False, lambda v: f"{v:.3f}"),
        ("cs", "CS (Chunk Stickiness) â†“", True, lambda v: f"{v:.3f}"),
        ("chunk_count", "Chunk Count", False, lambda v: f"{int(v)}"),
        ("bc_std", "BC Std (Consistency) â†“", True, lambda v: f"{v:.3f}"),
    ]

    # íŒŒì„œ ëª©ë¡ ìˆ˜ì§‘
    all_parsers = set()
    for test in chunking_data.values():
        all_parsers.update(test["parsers"].keys())
    parser_list = sorted(list(all_parsers))

    # 2x2 ì„œë¸Œí”Œë¡¯ ìƒì„±
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=[m[1] for m in metrics],
        horizontal_spacing=0.10,
        vertical_spacing=0.18,
    )

    # ê° ë©”íŠ¸ë¦­ë³„ë¡œ ë°” ì¶”ê°€
    for idx, (metric_key, title, lower_is_better, fmt) in enumerate(metrics):
        row = idx // 2 + 1
        col = idx % 2 + 1

        for parser_idx, parser in enumerate(parser_list):
            color = PARSER_COLORS.get(parser, DEFAULT_COLORS[parser_idx % len(DEFAULT_COLORS)])
            values = [
                test["parsers"].get(parser, {}).get(metric_key) or 0
                for test in chunking_data.values()
            ]

            # ì²« ë²ˆì§¸ ì„œë¸Œí”Œë¡¯ì—ì„œë§Œ legend í‘œì‹œ
            show_legend = (idx == 0)

            fig.add_trace(
                go.Bar(
                    name=parser,
                    x=test_ids,
                    y=values,
                    marker_color=color,
                    marker_line_width=0,
                    text=[fmt(v) if v else "N/A" for v in values],
                    textposition="outside",
                    textfont=dict(size=10),
                    showlegend=show_legend,
                    legendgroup=parser,
                ),
                row=row, col=col
            )

    # ë ˆì´ì•„ì›ƒ ì„¤ì •
    fig.update_layout(
        height=650,
        barmode="group",
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        font=dict(size=11, color="#666"),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.04,
            xanchor="left",
            x=0,
            font=dict(size=14),
        ),
        margin=dict(l=50, r=30, t=100, b=40),
        bargap=0.15,
        bargroupgap=0.05,
    )

    # ê° ì¶• ì„¤ì •
    for i in range(1, 5):
        fig.update_xaxes(showgrid=False, tickfont=dict(size=10), row=(i-1)//2+1, col=(i-1)%2+1)
        fig.update_yaxes(gridcolor="#E5E5E5", gridwidth=0.5, zeroline=False, tickfont=dict(size=10), row=(i-1)//2+1, col=(i-1)%2+1)

    # ì„œë¸Œí”Œë¡¯ íƒ€ì´í‹€ ìŠ¤íƒ€ì¼
    for annotation in fig['layout']['annotations']:
        annotation['font'] = dict(size=15, color="#1a1a2e", weight="bold")
        annotation['xanchor'] = 'left'
        if annotation['x'] < 0.5:
            annotation['x'] = 0.0
        else:
            annotation['x'] = 0.55

    return fig


def create_chunking_thin_bar_chart(data: Dict, metric: str, title: str,
                                    lower_is_better: bool = False) -> go.Figure:
    """Chunkingìš© ì–‡ì€ ê°€ë¡œí˜• Bar Chart"""
    parsers = list(data["parsers"].keys())
    values = [data["parsers"][p].get(metric) or 0 for p in parsers]
    colors = [PARSER_COLORS.get(p, "#888") for p in parsers]

    fig = go.Figure()

    # Format based on metric type
    if metric == "chunk_count":
        text_values = [f"{int(v)}" for v in values]
    else:
        text_values = [f"{v:.4f}" for v in values]

    fig.add_trace(go.Bar(
        y=parsers,
        x=values,
        orientation='h',
        marker_color=colors,
        marker_line_width=0,
        text=text_values,
        textposition="outside",
        textfont=dict(size=12, color="#333"),
    ))

    direction = "â† Lower is better" if lower_is_better else "Higher is better â†’"
    fig.update_layout(
        title=dict(text=title, font=dict(size=14, color="#1a1a2e"), x=0),
        height=180,
        margin=dict(l=10, r=80, t=40, b=25),
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        font=dict(size=12, color="#666"),
        xaxis=dict(showgrid=False, showticklabels=False, zeroline=False),
        yaxis=dict(showgrid=False, tickfont=dict(size=12)),
        showlegend=False,
        annotations=[dict(
            text=direction, x=1, y=-0.12, xref="paper", yref="paper",
            showarrow=False, font=dict(size=10, color="#888"), xanchor="right"
        )]
    )
    return fig


with tab_chunking:
    st.markdown("## Chunking Test Results")

    # Metrics ì •ì˜
    with st.expander("ğŸ“ Metrics ì •ì˜", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**BC (Boundary Clarity)** Â· :orange[â†‘ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("ì¸ì ‘ ì²­í¬ ê°„ ì˜ë¯¸ì  ë…ë¦½ì„±. `1 - cosine_similarity`")
            st.markdown("**CS (Chunk Stickiness)** Â· :green[â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("ì²­í¬ ê·¸ë˜í”„ì˜ êµ¬ì¡°ì  ì—”íŠ¸ë¡œí”¼. ì²­í¬ ê°„ ì—°ê²°ì„±.")
        with col2:
            st.markdown("**Chunk Count** Â· ë¬¸ì„œë‹¹ ì²­í¬ ìˆ˜")
            st.markdown("SemanticChunker ê¸°ë°˜ ìë™ ë¶„í•  ê²°ê³¼.")
            st.markdown("**BC Std** Â· :green[â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("BC í‘œì¤€í¸ì°¨. ì¼ê´€ëœ ê²½ê³„ í’ˆì§ˆ ì¸¡ì •.")

    st.markdown("---")

    # ì²­í‚¹ ë°ì´í„° ë¡œë“œ
    CHUNKING_DATA_DICT = get_chunking_data_dict(raw_data)
    tests_with_chunking = get_tests_with_chunking(raw_data)

    if not tests_with_chunking:
        st.warning("ì²­í‚¹ í…ŒìŠ¤íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("""
        **ì‹¤í–‰ ë°©ë²•:**
        ```bash
        python -m src.eval_chunking --parsed-dir results/test_1/ --verbose
        ```
        """)
    else:
        # =====================================================================
        # Global Performance Summary
        # =====================================================================
        st.markdown("### ğŸ“ˆ Global Performance Summary")

        col_table, col_chart = st.columns([2, 3])

        with col_table:
            # Summary DataFrame ìƒì„±
            summary_df = get_chunking_summary_df(raw_data)
            if not summary_df.empty:
                display_df = summary_df.copy()
                # ì»¬ëŸ¼ í¬ë§·íŒ…
                display_df["BC Score"] = display_df["BC Score"].apply(
                    lambda x: f"{x:.4f}" if pd.notna(x) else "N/A"
                )
                display_df["CS Score"] = display_df["CS Score"].apply(
                    lambda x: f"{x:.4f}" if pd.notna(x) else "N/A"
                )
                display_df = display_df.rename(columns={
                    "Test ID": "Test",
                    "BC Score": "BC â†‘",
                    "CS Score": "CS â†“",
                    "Chunk Count": "Chunks",
                })
                # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ í‘œì‹œ
                display_cols = ["Test", "Parser", "BC â†‘", "CS â†“", "Chunks"]
                display_df = display_df[[c for c in display_cols if c in display_df.columns]]

                st.dataframe(display_df, use_container_width=True, hide_index=True, height=350)

                # CSV ë‹¤ìš´ë¡œë“œ
                csv_data = export_df_to_csv(summary_df)
                st.download_button(
                    label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
                    data=csv_data,
                    file_name="chunking_summary.csv",
                    mime="text/csv",
                )
            else:
                st.info("í‘œì‹œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        with col_chart:
            # Bubble Chart - BC vs CS, size = Chunk Count
            if CHUNKING_DATA_DICT:
                # ë°ì´í„° ìˆ˜ì§‘
                plot_data = []
                for test_id, test_data in CHUNKING_DATA_DICT.items():
                    for parser, metrics in test_data["parsers"].items():
                        if metrics.get("bc") is not None and metrics.get("cs") is not None:
                            plot_data.append({
                                "parser": parser,
                                "test_id": test_id,
                                "bc": metrics.get("bc", 0),
                                "cs": metrics.get("cs", 0),
                                "chunks": metrics.get("chunk_count", 1),
                            })

                if plot_data:
                    # íŒŒì„œë³„ ìƒ‰ìƒ ë§¤í•‘
                    unique_parsers = sorted(list(set(d["parser"] for d in plot_data)))
                    colors = ["#e41a1c", "#377eb8", "#4daf4a", "#984ea3", "#ff7f00", "#a65628", "#f781bf", "#999999"]

                    fig = go.Figure()

                    for i, parser in enumerate(unique_parsers):
                        parser_data = [d for d in plot_data if d["parser"] == parser]
                        # ë²„ë¸” í¬ê¸° ì •ê·œí™” (min 15, max 50)
                        chunks = [d["chunks"] for d in parser_data]
                        max_chunks = max(d["chunks"] for d in plot_data)
                        min_chunks = min(d["chunks"] for d in plot_data)
                        if max_chunks > min_chunks:
                            sizes = [15 + (c - min_chunks) / (max_chunks - min_chunks) * 35 for c in chunks]
                        else:
                            sizes = [25] * len(chunks)

                        fig.add_trace(go.Scatter(
                            x=[d["bc"] for d in parser_data],
                            y=[d["cs"] for d in parser_data],
                            mode="markers",
                            name=parser,
                            marker=dict(
                                size=sizes,
                                color=colors[i % len(colors)],
                                opacity=0.7,
                                line=dict(width=2, color="white"),
                            ),
                            text=[f"{d['test_id']}<br>Chunks: {d['chunks']}" for d in parser_data],
                            hovertemplate="<b>%{text}</b><br>BC: %{x:.3f}<br>CS: %{y:.2f}<extra></extra>",
                        ))

                    fig.update_layout(
                        title=dict(text="BC vs CS (size=Chunks)", font=dict(size=14, color="#1a1a2e"), x=0),
                        xaxis=dict(title="BC (Boundary Clarity) â†‘", gridcolor="#eee"),
                        yaxis=dict(title="CS (Chunk Stickiness) â†“", gridcolor="#eee"),
                        height=350,
                        margin=dict(l=60, r=20, t=50, b=50),
                        paper_bgcolor="rgba(0,0,0,0)",
                        plot_bgcolor="rgba(0,0,0,0)",
                        font=dict(size=11, color="#666"),
                        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="center", x=0.5),
                        showlegend=True,
                    )

                    st.plotly_chart(fig, use_container_width=True, config=get_chart_download_config("chunking_bubble"))
                else:
                    st.info("ì°¨íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ì°¨íŠ¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # =====================================================================
        # Metrics Comparison - í†µí•© Subplot ì°¨íŠ¸
        # =====================================================================
        if CHUNKING_DATA_DICT:
            st.markdown("#### Metrics Comparison")

            metrics_fig = create_chunking_metrics_subplot(CHUNKING_DATA_DICT)
            st.plotly_chart(
                metrics_fig,
                use_container_width=True,
                config=get_chart_download_config("chunking_metrics_comparison")
            )

        st.markdown("---")

        # =====================================================================
        # Detailed Test Analysis
        # =====================================================================
        st.markdown("### ğŸ”¬ Detailed Test Analysis")

        # í˜ì´ì§€ë„¤ì´ì…˜ (10ê°œ ì´ˆê³¼ ì‹œ)
        chunking_items = list(CHUNKING_DATA_DICT.items())
        total_chunking_tests = len(chunking_items)

        if total_chunking_tests > PAGE_SIZE:
            col_page_info, col_page_nav = st.columns([2, 1])

            with col_page_info:
                st.caption(f"ì´ {total_chunking_tests}ê°œ í…ŒìŠ¤íŠ¸ (í˜ì´ì§€ë‹¹ {PAGE_SIZE}ê°œ)")

            if "chunking_page" not in st.session_state:
                st.session_state.chunking_page = 1

            total_pages = (total_chunking_tests + PAGE_SIZE - 1) // PAGE_SIZE

            with col_page_nav:
                page = st.number_input(
                    "Page",
                    min_value=1,
                    max_value=total_pages,
                    value=st.session_state.chunking_page,
                    key="chunking_page_input"
                )
                st.session_state.chunking_page = page

            paginated_chunking_items, _, _, _ = paginate_data(chunking_items, page, PAGE_SIZE)
        else:
            paginated_chunking_items = chunking_items

        # í…ŒìŠ¤íŠ¸ë³„ ìƒì„¸ (Expander)
        for test_id, test_data in paginated_chunking_items:
            metadata = test_data.get("metadata", {})
            title = metadata.get("title", test_id)
            config = test_data.get("config", {})

            test_num = test_id.replace("test_", "").replace("_", " ").title()
            total_chunks = sum(p.get("chunk_count", 0) for p in test_data["parsers"].values())

            expander_title = f"ğŸ“¦ **Test {test_num}**: {title} ({total_chunks} chunks)"

            with st.expander(expander_title, expanded=False):
                # ì„¤ì • ì •ë³´
                info_cols = st.columns([2, 1, 1])
                with info_cols[0]:
                    st.caption(f"ğŸ“ {title}")
                with info_cols[1]:
                    strategy = config.get("breakpoint_type", "semantic")
                    st.caption(f"âš™ï¸ Strategy: {strategy}")
                with info_cols[2]:
                    threshold = config.get("breakpoint_threshold", "N/A")
                    st.caption(f"ğŸ¯ Threshold: {threshold}")
                st.divider()

                # í…Œì´ë¸”
                detail_rows = []
                for parser, metrics in test_data["parsers"].items():
                    bc_val = metrics.get("bc")
                    cs_val = metrics.get("cs")
                    bc_std = metrics.get("bc_std")

                    detail_rows.append({
                        "Parser": parser,
                        "BC â†‘": f"{bc_val:.4f}" if bc_val is not None else "N/A",
                        "CS â†“": f"{cs_val:.4f}" if cs_val is not None else "N/A",
                        "BC Std": f"Â±{bc_std:.4f}" if bc_std is not None else "-",
                        "Chunks": metrics.get("chunk_count", 0),
                    })
                st.dataframe(pd.DataFrame(detail_rows), use_container_width=True, hide_index=True)

                # Bar Charts
                chart_cols = st.columns(2)
                with chart_cols[0]:
                    st.plotly_chart(
                        create_chunking_thin_bar_chart(test_data, "bc", "BC (Boundary Clarity)", lower_is_better=False),
                        use_container_width=True,
                        config=get_chart_download_config(f"{test_id}_bc")
                    )
                    st.plotly_chart(
                        create_chunking_thin_bar_chart(test_data, "cs", "CS (Chunk Stickiness)", lower_is_better=True),
                        use_container_width=True,
                        config=get_chart_download_config(f"{test_id}_cs")
                    )
                with chart_cols[1]:
                    st.plotly_chart(
                        create_chunking_thin_bar_chart(test_data, "chunk_count", "Chunk Count", lower_is_better=False),
                        use_container_width=True,
                        config=get_chart_download_config(f"{test_id}_chunks")
                    )
                    if any(test_data["parsers"][p].get("bc_std") for p in test_data["parsers"]):
                        st.plotly_chart(
                            create_chunking_thin_bar_chart(test_data, "bc_std", "BC Std (Consistency)", lower_is_better=True),
                            use_container_width=True,
                            config=get_chart_download_config(f"{test_id}_bc_std")
                        )



# =============================================================================
# TAB 3: ì¢…í•© ë¶„ì„
# =============================================================================

with tab_result:
    st.markdown("## ğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼")
    st.markdown("> Parsingê³¼ Chunking ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ í’ˆì§ˆì„ ì§„ë‹¨í•©ë‹ˆë‹¤.")

    st.markdown("---")

    st.markdown("### ğŸ¯ í•µì‹¬ ë°œê²¬ì‚¬í•­")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        #### Parsing ê´€ì 

        1. **VLMì´ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜**
           - ëŒ€ë¶€ë¶„ì˜ í…ŒìŠ¤íŠ¸ì—ì„œ ìµœì € WER ë‹¬ì„±
           - íŠ¹íˆ ì´ë¯¸ì§€ ê¸°ë°˜ ë¬¸ì„œì—ì„œ ì••ë„ì 

        2. **Trade-off ì¡´ì¬**
           - ì •í™•ë„ â†” ì²˜ë¦¬ ì‹œê°„
           - ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ì—ëŠ” pdfplumber ê³ ë ¤

        3. **ë¬¸ì„œ ìœ í˜•ë³„ ì°¨ì´ í¼**
           - ìŠ¤ìº” ì´ë¯¸ì§€: VLM í•„ìˆ˜
           - ë””ì§€í„¸ PDF: pdfplumberë„ ì¶©ë¶„
        """)

    with col2:
        st.markdown("""
        #### Chunking ê´€ì 

        1. **Semantic Chunking ê¶Œì¥**
           - BCê°€ ê°€ì¥ ë†’ì€ ê²½ê³„ ëª…í™•ë„
           - CSê°€ ë‚®ì€ ë‚´ë¶€ ì˜ì¡´ì„±

        2. **Fixed Chunking ì£¼ì˜**
           - ì˜ë¯¸ ê²½ê³„ ë¬´ì‹œë¡œ BC ë‚®ìŒ
           - RAG ì„±ëŠ¥ ì €í•˜ ìš°ë ¤

        3. **ìµœì  íŒŒë¼ë¯¸í„°**
           - Chunk Size: 400-600
           - Overlap: 50-100
        """)

    st.markdown("---")

    st.markdown("### ğŸš€ ë‹¤ìŒ ë‹¨ê³„")
    st.markdown("""
    | ìš°ì„ ìˆœìœ„ | ì‘ì—… | ëª©ì  |
    |---------|------|------|
    | 1 | Golden Dataset êµ¬ì¶• | í‰ê°€ ì‹ ë¢°ë„ í–¥ìƒ |
    | 2 | VLM SFT í•™ìŠµ | êµ¬ì¡°í™” ì„±ëŠ¥ ê°œì„  |
    | 3 | Semantic Chunking ì ìš© | RAG í’ˆì§ˆ í–¥ìƒ |
    | 4 | ì¶”ê°€ ë¬¸ì„œ ìœ í˜• í…ŒìŠ¤íŠ¸ | ì¼ë°˜í™” ê²€ì¦ |
    """)

    st.markdown("---")
    st.caption(f"VLM Document Parsing Quality Analysis | {VERSION}")
