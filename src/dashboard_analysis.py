"""
VLM Document Parsing Quality Analysis Dashboard

CLI í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ì—¬ Tech Report ì‘ì„±ì„ ì§€ì›í•˜ëŠ” ì •ì  ëŒ€ì‹œë³´ë“œ

Features:
- JSON ê²°ê³¼ íŒŒì¼ ë¡œë“œ (results/parsing_results.json)
- @st.cache_data ìºì‹± (1ì‹œê°„ TTL)
- í˜ì´ì§€ë„¤ì´ì…˜ (10ê°œ í…ŒìŠ¤íŠ¸ ì´ˆê³¼ ì‹œ)
- ì°¨íŠ¸ PNG ë‹¤ìš´ë¡œë“œ
- CSV ë‚´ë³´ë‚´ê¸°

Usage:
    streamlit run src/dashboard_analysis.py
"""

import sys
from pathlib import Path

_src_dir = Path(__file__).parent
if str(_src_dir) not in sys.path:
    sys.path.insert(0, str(_src_dir))

import streamlit as st
import pandas as pd
import plotly.graph_objects as go
from typing import Dict, List, Any
import numpy as np

from dashboard.data_loader import (
    load_results_cached,
    get_parsing_data,
    get_chunking_data,
    get_chunking_data_for_parser,
    get_chunking_parsers,
    get_parser_names,
    get_parsing_summary_df,
    get_chunking_summary_df,
    get_chart_download_config,
    export_df_to_csv,
    paginate_data,
    get_sample_data,
)
from dashboard.charts import (
    STRATEGY_COLORS as CHART_STRATEGY_COLORS,
    create_parser_chunking_comparison,
    create_bc_document_flow,
    create_cs_mean_std_bar,
)

# =============================================================================
# í˜ì´ì§€ ì„¤ì •
# =============================================================================

st.set_page_config(
    page_title="VLM Document Parsing Quality Analysis",
    page_icon="ğŸ“„",
    layout="wide",
    initial_sidebar_state="collapsed",
)

# =============================================================================
# ìŠ¤íƒ€ì¼ ì„¤ì •
# =============================================================================

st.markdown("""
<style>
    /* Sidebar ì™„ì „ ìˆ¨ê¹€ */
    [data-testid="stSidebar"] { display: none; }
    [data-testid="stSidebarCollapsedControl"] { display: none; }

    /* ì „ì²´ ë°°ê²½ */
    .stApp { background-color: #FAFAFA; }

    /* í—¤ë” */
    h1, h2, h3 { color: #1a1a2e !important; font-weight: 600 !important; }

    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    [data-testid="stMetric"] {
        background-color: #FFFFFF;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #E5E5E5;
    }
    [data-testid="stMetricValue"] { color: #1a1a2e !important; font-size: 1.5rem !important; }
    [data-testid="stMetricLabel"] { color: #666666 !important; }

    /* íƒ­ */
    .stTabs [data-baseweb="tab-list"] { gap: 8px; border-bottom: 1px solid #E5E5E5; }
    .stTabs [data-baseweb="tab"] {
        color: #666666;
        font-weight: 500;
        padding: 0.75rem 1.5rem;
    }
    .stTabs [aria-selected="true"] {
        color: #1a1a2e !important;
        border-bottom: 2px solid #4F46E5 !important;
    }

    /* í…Œì´ë¸” */
    .stDataFrame { border-radius: 8px; }

    /* êµ¬ë¶„ì„  */
    hr { border-color: #E5E5E5; margin: 2rem 0; }

    /* ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ */
    .download-btn {
        background-color: #F3F4F6;
        border: 1px solid #E5E5E5;
        border-radius: 6px;
        padding: 0.5rem 1rem;
        font-size: 0.875rem;
        cursor: pointer;
    }
</style>
""", unsafe_allow_html=True)

# =============================================================================
# ìƒìˆ˜
# =============================================================================

VERSION = "v0.4.0"  # Added parser-specific chunking analysis (MoC-based)
PAGE_SIZE = 10  # í˜ì´ì§€ë„¤ì´ì…˜ í¬ê¸°

# ë™ì  ìƒ‰ìƒ ìƒì„± (íŒŒì„œ ì¶”ê°€ ì‹œ ìë™ í™•ì¥)
DEFAULT_COLORS = ["#4F46E5", "#059669", "#D97706", "#DC2626", "#7C3AED", "#0891B2"]

def get_parser_colors(parsers: List[str]) -> Dict[str, str]:
    """íŒŒì„œë³„ ìƒ‰ìƒ ë™ì  ìƒì„±"""
    colors = {}
    for i, parser in enumerate(parsers):
        colors[parser] = DEFAULT_COLORS[i % len(DEFAULT_COLORS)]
    return colors

# ì²­í‚¹ ì „ëµ ìƒ‰ìƒ
STRATEGY_COLORS = {
    "Fixed": "#6366F1",
    "Sentence": "#10B981",
    "Semantic": "#F59E0B",
    "Structuring": "#8B5CF6",
}


# =============================================================================
# ë°ì´í„° ë¡œë“œ
# =============================================================================

@st.cache_data(ttl=3600)
def load_data():
    """Load data with caching"""
    data = load_results_cached()
    if "error" in data:
        # Fallback to sample data
        return get_sample_data(), True
    return data, False


# ë°ì´í„° ë¡œë“œ
raw_data, is_sample = load_data()

# íŒŒì„œ ìƒ‰ìƒ
PARSER_NAMES = get_parser_names(raw_data)
PARSER_COLORS = get_parser_colors(PARSER_NAMES)

# ë³€í™˜ëœ ë°ì´í„°
PARSING_DATA = get_parsing_data(raw_data)
CHUNKING_DATA = get_chunking_data(raw_data)


# =============================================================================
# ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
# =============================================================================

def hex_to_rgba(hex_color: str, alpha: float = 0.1) -> str:
    """Hex ìƒ‰ìƒì„ rgbaë¡œ ë³€í™˜"""
    hex_color = hex_color.lstrip('#')
    r = int(hex_color[0:2], 16)
    g = int(hex_color[2:4], 16)
    b = int(hex_color[4:6], 16)
    return f"rgba({r},{g},{b},{alpha})"


def create_thin_bar_chart(data: Dict, metric: str, title: str,
                          lower_is_better: bool = False) -> go.Figure:
    """ì–‡ì€ ê°€ë¡œí˜• Bar Chart"""
    parsers = list(data["parsers"].keys())
    values = [data["parsers"][p].get(metric, 0) for p in parsers]
    colors = [PARSER_COLORS.get(p, "#888") for p in parsers]

    fig = go.Figure()
    fig.add_trace(go.Bar(
        y=parsers,
        x=values,
        orientation='h',
        marker_color=colors,
        marker_line_width=0,
        text=[f"{v:.3f}" if metric != "latency" else f"{v:,}ms" for v in values],
        textposition="outside",
        textfont=dict(size=11, color="#666"),
    ))

    direction = "â† Lower is better" if lower_is_better else "Higher is better â†’"
    fig.update_layout(
        title=dict(text=title, font=dict(size=13, color="#1a1a2e"), x=0),
        height=160,
        margin=dict(l=0, r=60, t=35, b=5),
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        font=dict(size=11, color="#666"),
        xaxis=dict(showgrid=False, showticklabels=False, zeroline=False),
        yaxis=dict(showgrid=False, tickfont=dict(size=10)),
        showlegend=False,
        annotations=[dict(
            text=direction, x=1, y=-0.15, xref="paper", yref="paper",
            showarrow=False, font=dict(size=9, color="#999"), xanchor="right"
        )]
    )
    return fig


def create_radar_chart(all_data: Dict) -> go.Figure:
    """íŒŒì„œë³„ ì„±ëŠ¥ Radar Chart"""
    metrics = ["WER", "CER", "BLEU", "Latency"]
    fig = go.Figure()

    for parser in PARSER_NAMES:
        values = []
        for metric_key in ["wer", "cer", "bleu", "latency"]:
            vals = [
                test["parsers"][parser].get(metric_key, 0)
                for test in all_data.values()
                if parser in test["parsers"]
            ]
            avg = np.mean(vals) if vals else 0

            # ì •ê·œí™” (ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ ê²ƒì€ ë°˜ì „)
            if metric_key in ["wer", "cer"]:
                normalized = 1 - min(avg, 1)
            elif metric_key == "latency":
                normalized = 1 - min(avg / 15000, 1)
            else:
                normalized = avg
            values.append(normalized)

        values.append(values[0])  # ë‹«ê¸°

        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=metrics + [metrics[0]],
            name=parser,
            line=dict(color=PARSER_COLORS.get(parser, "#888"), width=3),
            fill='toself',
            fillcolor=hex_to_rgba(PARSER_COLORS.get(parser, "#888"), 0.1),
        ))

    fig.update_layout(
        polar=dict(
            radialaxis=dict(visible=True, range=[0, 1], showticklabels=False, gridcolor="#E5E5E5"),
            angularaxis=dict(tickfont=dict(size=11, color="#666"), gridcolor="#E5E5E5"),
            bgcolor="rgba(0,0,0,0)",
        ),
        showlegend=True,
        legend=dict(orientation="h", yanchor="bottom", y=-0.2, xanchor="center", x=0.5, font=dict(size=10)),
        height=350,
        margin=dict(l=60, r=60, t=30, b=60),
        paper_bgcolor="rgba(0,0,0,0)",
    )
    return fig


def create_bc_cs_scatter(chunking_data: Dict) -> go.Figure:
    """BC vs CS Scatter Plot"""
    fig = go.Figure()

    for strategy, data in chunking_data.items():
        bc_values = [c.get("bc", 0) for c in data.get("chunks", [])]
        cs_values = [c.get("cs", 0) for c in data.get("chunks", [])]

        if not bc_values:
            continue

        fig.add_trace(go.Scatter(
            x=bc_values, y=cs_values, mode='markers', name=strategy,
            marker=dict(
                size=12,
                color=STRATEGY_COLORS.get(strategy, "#888"),
                line=dict(width=1, color="white"),
                opacity=0.8,
            ),
            hovertemplate=f"<b>{strategy}</b><br>BC: %{{x:.2f}}<br>CS: %{{y:.2f}}<extra></extra>",
        ))

    # Quadrant ì˜ì—­
    fig.add_shape(type="rect", x0=0.5, x1=1, y0=0, y1=0.5,
                  fillcolor="rgba(16, 185, 129, 0.05)", line_width=0)
    fig.add_shape(type="rect", x0=0, x1=0.5, y0=0.5, y1=1,
                  fillcolor="rgba(239, 68, 68, 0.05)", line_width=0)

    fig.add_hline(y=0.5, line_dash="dot", line_color="#ccc", line_width=1)
    fig.add_vline(x=0.5, line_dash="dot", line_color="#ccc", line_width=1)

    annotations = [
        dict(x=0.75, y=0.25, text="ì´ìƒì <br>(BCâ†‘ CSâ†“)", showarrow=False,
             font=dict(size=9, color="#059669"), opacity=0.7),
        dict(x=0.25, y=0.75, text="Over-merge<br>(BCâ†“ CSâ†‘)", showarrow=False,
             font=dict(size=9, color="#DC2626"), opacity=0.7),
        dict(x=0.75, y=0.75, text="Fragmentation<br>(BCâ†‘ CSâ†‘)", showarrow=False,
             font=dict(size=9, color="#D97706"), opacity=0.7),
        dict(x=0.25, y=0.25, text="Structural<br>Failure", showarrow=False,
             font=dict(size=9, color="#6B7280"), opacity=0.7),
    ]

    fig.update_layout(
        title=dict(text="BCâ€“CS Distribution by Strategy", font=dict(size=14, color="#1a1a2e"), x=0),
        xaxis=dict(title="Boundary Clarity (BC) â†’", range=[0, 1], gridcolor="#E5E5E5", zeroline=False),
        yaxis=dict(title="Chunk Stickiness (CS) â†“", range=[0, 1], gridcolor="#E5E5E5", zeroline=False),
        height=450, margin=dict(l=60, r=30, t=50, b=50),
        paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0, font=dict(size=10)),
        annotations=annotations,
    )
    return fig


def create_grouped_bar(all_data: Dict, metric: str, title: str, lower_is_better: bool = False) -> go.Figure:
    """ì „ì²´ í…ŒìŠ¤íŠ¸ ë¹„êµ Grouped Bar Chart"""
    test_ids = [d["id"] for d in all_data.values()]
    fig = go.Figure()

    for parser in PARSER_NAMES:
        color = PARSER_COLORS.get(parser, "#888")
        values = [test["parsers"].get(parser, {}).get(metric, 0) for test in all_data.values()]
        fig.add_trace(go.Bar(
            name=parser, x=test_ids, y=values,
            marker_color=color, marker_line_width=0,
            text=[f"{v:.2f}" if metric != "latency" else f"{v/1000:.1f}s" for v in values],
            textposition="outside", textfont=dict(size=9), width=0.25,
        ))

    direction = "â†“ Lower is better" if lower_is_better else "â†‘ Higher is better"
    fig.update_layout(
        title=dict(text=f"{title} ({direction})", font=dict(size=13, color="#1a1a2e"), x=0),
        barmode="group", height=280,
        margin=dict(l=40, r=20, t=50, b=60),
        paper_bgcolor="rgba(0,0,0,0)", plot_bgcolor="rgba(0,0,0,0)",
        font=dict(size=10, color="#666"),
        xaxis=dict(showgrid=False, tickfont=dict(size=10)),
        yaxis=dict(gridcolor="#E5E5E5", gridwidth=0.5, zeroline=False),
        legend=dict(orientation="h", yanchor="top", y=-0.15, xanchor="left", x=0, font=dict(size=9)),
        bargap=0.3, bargroupgap=0.1,
    )
    return fig


# =============================================================================
# ë©”ì¸ ëŒ€ì‹œë³´ë“œ
# =============================================================================

# í—¤ë”
st.title("ğŸ“„ VLM Document Parsing Quality Analysis")
st.caption(f"CLI í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì‹œê°í™” | Tech Report ì‘ì„± ì§€ì› | {VERSION}")

# ìƒ˜í”Œ ë°ì´í„° ê²½ê³ 
if is_sample:
    st.warning("âš ï¸ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤. CLIì—ì„œ í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# ë°ì´í„° ì •ë³´
data_info_cols = st.columns([1, 1, 1, 2])
with data_info_cols[0]:
    st.metric("Total Tests", len(PARSING_DATA))
with data_info_cols[1]:
    st.metric("Parsers", len(PARSER_NAMES))
with data_info_cols[2]:
    st.metric("Strategies", len(CHUNKING_DATA))
with data_info_cols[3]:
    created_at = raw_data.get("created_at", "N/A")
    st.caption(f"Data Version: {raw_data.get('version', 'N/A')} | Created: {created_at}")

st.markdown("---")

# íƒ­ êµ¬ì„±
tab_parsing, tab_chunking, tab_result = st.tabs([
    "ğŸ” Parsing Test",
    "ğŸ“¦ Chunking Test",
    "ğŸ“Š ì¢…í•© ë¶„ì„"
])


# =============================================================================
# TAB 1: Parsing Test
# =============================================================================

with tab_parsing:
    st.markdown("## Parsing Test Results")

    # Metrics ì •ì˜
    with st.expander("ğŸ“ Metrics ì •ì˜", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**WER (Word Error Rate)** Â· :green[â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("Mecab ê¸°ë°˜ ë‹¨ì–´ ë‹¨ìœ„ ì˜¤ë¥˜ìœ¨. ì‚½ì…/ì‚­ì œ/ëŒ€ì²´ ì˜¤ë¥˜ ì¢…í•©.")
            st.markdown("**CER (Character Error Rate)** Â· :green[â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("ë¬¸ì ë‹¨ìœ„ ì˜¤ë¥˜ìœ¨. ëˆ„ë½/ì¶”ê°€/ë³€ê²½ ë¬¸ì ì¶”ì .")
        with col2:
            st.markdown("**BLEU Score** Â· :orange[â†‘ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ (ë³´ì¡°)]")
            st.markdown("í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€. n-gram ì •ë°€ë„.")
            st.markdown("**Latency** Â· :green[â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("ë¬¸ì„œ 1ê±´ Parsing ì²˜ë¦¬ ì‹œê°„ (ms).")

    st.markdown("---")

    # Global Performance Summary
    st.markdown("### ğŸ“ˆ Global Performance Summary")

    col_table, col_radar = st.columns([1, 1])

    with col_table:
        # DataFrame ìƒì„±
        summary_df = get_parsing_summary_df(raw_data)
        display_df = summary_df[["Test", "Parser", "WER", "CER", "BLEU", "Latency (ms)"]].copy()
        display_df["WER"] = display_df["WER"].apply(lambda x: f"{x:.3f}")
        display_df["CER"] = display_df["CER"].apply(lambda x: f"{x:.3f}")
        display_df["BLEU"] = display_df["BLEU"].apply(lambda x: f"{x:.3f}")
        display_df["Latency (ms)"] = display_df["Latency (ms)"].apply(lambda x: f"{x:,.0f}ms")

        st.dataframe(display_df, use_container_width=True, hide_index=True, height=350)

        # CSV ë‹¤ìš´ë¡œë“œ
        csv_data = export_df_to_csv(summary_df)
        st.download_button(
            label="ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ",
            data=csv_data,
            file_name="parsing_summary.csv",
            mime="text/csv",
        )

    with col_radar:
        radar_fig = create_radar_chart(PARSING_DATA)
        st.plotly_chart(
            radar_fig,
            width="stretch",
            config=get_chart_download_config("radar_chart")
        )

    # Metrics Comparison
    st.markdown("#### Metrics Comparison")

    row1 = st.columns(2)
    row2 = st.columns(2)

    with row1[0]:
        st.plotly_chart(
            create_grouped_bar(PARSING_DATA, "wer", "WER", lower_is_better=True),
            width="stretch",
            config=get_chart_download_config("wer_comparison")
        )
    with row1[1]:
        st.plotly_chart(
            create_grouped_bar(PARSING_DATA, "cer", "CER", lower_is_better=True),
            width="stretch",
            config=get_chart_download_config("cer_comparison")
        )
    with row2[0]:
        st.plotly_chart(
            create_grouped_bar(PARSING_DATA, "bleu", "BLEU", lower_is_better=False),
            width="stretch",
            config=get_chart_download_config("bleu_comparison")
        )
    with row2[1]:
        st.plotly_chart(
            create_grouped_bar(PARSING_DATA, "latency", "Latency", lower_is_better=True),
            width="stretch",
            config=get_chart_download_config("latency_comparison")
        )

    st.markdown("---")

    # Detailed Test Analysis with Pagination
    st.markdown("### ğŸ”¬ Detailed Test Analysis")

    # í˜ì´ì§€ë„¤ì´ì…˜ (10ê°œ ì´ˆê³¼ ì‹œ)
    test_items = list(PARSING_DATA.items())
    total_tests = len(test_items)

    if total_tests > PAGE_SIZE:
        # í˜ì´ì§€ ì„ íƒ
        col_page_info, col_page_nav = st.columns([2, 1])

        with col_page_info:
            st.caption(f"ì´ {total_tests}ê°œ í…ŒìŠ¤íŠ¸ (í˜ì´ì§€ë‹¹ {PAGE_SIZE}ê°œ)")

        # í˜ì´ì§€ ìƒíƒœ
        if "parsing_page" not in st.session_state:
            st.session_state.parsing_page = 1

        total_pages = (total_tests + PAGE_SIZE - 1) // PAGE_SIZE

        with col_page_nav:
            page = st.number_input(
                "Page",
                min_value=1,
                max_value=total_pages,
                value=st.session_state.parsing_page,
                key="parsing_page_input"
            )
            st.session_state.parsing_page = page

        # í˜„ì¬ í˜ì´ì§€ ë°ì´í„°
        paginated_items, _, _, _ = paginate_data(test_items, page, PAGE_SIZE)
    else:
        paginated_items = test_items

    # í…ŒìŠ¤íŠ¸ë³„ ìƒì„¸ (Lazy Loading via Expander)
    for test_id, test_data in paginated_items:
        with st.expander(f"**{test_data['id']}: {test_data['name']}** ({test_data['doc_type']})", expanded=False):
            # í…Œì´ë¸”
            detail_rows = []
            for parser, metrics in test_data["parsers"].items():
                detail_rows.append({
                    "Parser": parser,
                    "WER â†“": f"{metrics.get('wer', 0):.3f}",
                    "CER â†“": f"{metrics.get('cer', 0):.3f}",
                    "BLEU â†‘": f"{metrics.get('bleu', 0):.3f}",
                    "Latency â†“": f"{metrics.get('latency', 0):,}ms",
                })
            st.dataframe(pd.DataFrame(detail_rows), use_container_width=True, hide_index=True)

            # Bar Charts
            chart_cols = st.columns(2)
            with chart_cols[0]:
                st.plotly_chart(
                    create_thin_bar_chart(test_data, "wer", "WER", lower_is_better=True),
                    width="stretch",
                    config=get_chart_download_config(f"{test_id}_wer")
                )
                st.plotly_chart(
                    create_thin_bar_chart(test_data, "bleu", "BLEU", lower_is_better=False),
                    width="stretch",
                    config=get_chart_download_config(f"{test_id}_bleu")
                )
            with chart_cols[1]:
                st.plotly_chart(
                    create_thin_bar_chart(test_data, "cer", "CER", lower_is_better=True),
                    width="stretch",
                    config=get_chart_download_config(f"{test_id}_cer")
                )
                st.plotly_chart(
                    create_thin_bar_chart(test_data, "latency", "Latency", lower_is_better=True),
                    width="stretch",
                    config=get_chart_download_config(f"{test_id}_latency")
                )


# =============================================================================
# TAB 2: Chunking Test
# =============================================================================

with tab_chunking:
    st.markdown("## Chunking Quality Analysis")
    st.markdown("> íŒŒì‹± ê²°ê³¼ê°€ Semantic Chunking í’ˆì§ˆì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.")

    # Metrics ì •ì˜
    with st.expander("ğŸ“ BC / CS Metrics ì •ì˜ (MoC Paper ê¸°ë°˜)", expanded=False):
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**Boundary Clarity (BC)** Â· :orange[â†‘ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("ì²­í¬ ê²½ê³„ì˜ ì˜ë¯¸ì  ëª…í™•ì„±. ë¬¸ì¥ ë‹¨ìœ„ë¡œ ê²½ê³„ íƒ€ë‹¹ì„± í‰ê°€.")
            st.markdown("- 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ê²½ê³„ê°€ ì˜ë¯¸ ë‹¨ìœ„ì™€ ì¼ì¹˜")
            st.markdown("- MoC Paper: 'Document Flow' ê·¸ë˜í”„ë¡œ ì‹œê°í™”")
        with col2:
            st.markdown("**Chunk Stickiness (CS)** Â· :green[â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ]")
            st.markdown("ì²­í¬ ë‚´ë¶€ ë¬¸ì¥ ê°„ í‰ê·  ìœ ì‚¬ë„ (Avg. Intra-chunk Similarity).")
            st.markdown("- 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì²­í¬ ë‚´ë¶€ê°€ ë…ë¦½ì ")
            st.markdown("- Structuring ì „ëµì€ N/A (êµ¬ì¡° ê¸°ë°˜ ë¶„í• )")

    st.markdown("---")

    # =========================================================================
    # íŒŒì„œ ì„ íƒ ë° ë¹„êµ ì„¹ì…˜
    # =========================================================================
    st.markdown("### ğŸ”„ Parserë³„ Chunking í’ˆì§ˆ ë¹„êµ")

    # ì²­í‚¹ ê²°ê³¼ê°€ ìˆëŠ” íŒŒì„œ ëª©ë¡
    chunking_parsers = get_chunking_parsers(raw_data)

    if not chunking_parsers or chunking_parsers == ["_legacy"]:
        st.info("íŒŒì„œë³„ ì²­í‚¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. v1.1 í˜•ì‹ì˜ ê²°ê³¼ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        # íŒŒì„œ ë¹„êµ ì°¨íŠ¸ (ì „ì²´ íŒŒì„œ Ã— ì „ëµë³„ BC/CS)
        st.markdown("#### ì „ëµë³„ íŒŒì„œ ì„±ëŠ¥ ë¹„êµ")

        # ì „ëµ ì„ íƒ
        all_strategies = set()
        for parser in chunking_parsers:
            strategies = get_chunking_data_for_parser(raw_data, parser)
            for s in strategies:
                all_strategies.add(s.get("strategy", "unknown"))

        strategy_list = sorted(list(all_strategies))
        if strategy_list:
            selected_strategy = st.selectbox(
                "ë¹„êµí•  ì „ëµ ì„ íƒ",
                options=strategy_list,
                index=strategy_list.index("Semantic") if "Semantic" in strategy_list else 0,
                key="chunking_strategy_select"
            )

            # Parser Comparison Chart
            comparison_fig = create_parser_chunking_comparison(
                CHUNKING_DATA,
                selected_strategy,
                title=f"{selected_strategy} Chunking: Parserë³„ BC/CS ë¹„êµ"
            )
            st.plotly_chart(
                comparison_fig,
                use_container_width=True,
                config=get_chart_download_config(f"parser_comparison_{selected_strategy}")
            )

        st.markdown("---")

        # =========================================================================
        # íŒŒì„œë³„ ìƒì„¸ ë¶„ì„ ì„¹ì…˜
        # =========================================================================
        st.markdown("### ğŸ“Š Parserë³„ ìƒì„¸ ë¶„ì„")

        # íŒŒì„œ ì„ íƒ ë“œë¡­ë‹¤ìš´
        selected_parser = st.selectbox(
            "ë¶„ì„í•  íŒŒì„œ ì„ íƒ",
            options=chunking_parsers,
            index=0,
            key="chunking_parser_select"
        )

        # ì„ íƒëœ íŒŒì„œì˜ ì „ëµ ë°ì´í„°
        parser_strategies = get_chunking_data_for_parser(raw_data, selected_parser)

        if not parser_strategies:
            st.warning(f"{selected_parser}ì˜ ì²­í‚¹ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            # KPI ì¹´ë“œ
            st.markdown(f"#### {selected_parser} ì „ëµë³„ ìš”ì•½")
            kpi_cols = st.columns(len(parser_strategies) + 1)

            with kpi_cols[0]:
                total_strategies = len(parser_strategies)
                st.metric("Strategies", total_strategies)

            for i, strategy_data in enumerate(parser_strategies):
                strategy_name = strategy_data.get("strategy", "unknown")
                mean_bc = strategy_data.get("mean_bc", 0)
                mean_cs = strategy_data.get("mean_cs")

                with kpi_cols[i + 1]:
                    # CSê°€ N/Aì¸ ê²½ìš° (Structuring)
                    cs_display = f"{mean_cs:.2f}" if mean_cs is not None else "N/A"
                    st.metric(
                        strategy_name,
                        f"BC: {mean_bc:.2f}",
                        f"CS: {cs_display}",
                        delta_color="off"
                    )

            # 2ì—´ ë ˆì´ì•„ì›ƒ: BC Document Flow + CS MeanÂ±Std
            chart_col1, chart_col2 = st.columns(2)

            with chart_col1:
                st.markdown("##### BC Document Flow")
                st.caption("ë¬¸ì¥ë³„ BC ê°’ê³¼ ì²­í¬ ê²½ê³„ ìœ„ì¹˜ (MoC Paper Fig.2 ìŠ¤íƒ€ì¼)")

                bc_flow_fig = create_bc_document_flow(
                    parser_strategies,
                    title=f"{selected_parser}: Boundary Clarity Flow"
                )
                st.plotly_chart(
                    bc_flow_fig,
                    use_container_width=True,
                    config=get_chart_download_config(f"bc_flow_{selected_parser}")
                )

            with chart_col2:
                st.markdown("##### CS Mean Â± Std")
                st.caption("ì „ëµë³„ Chunk Stickiness (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ, Structuringì€ N/A)")

                cs_bar_fig = create_cs_mean_std_bar(
                    parser_strategies,
                    title=f"{selected_parser}: Avg. Intra-chunk Similarity"
                )
                st.plotly_chart(
                    cs_bar_fig,
                    use_container_width=True,
                    config=get_chart_download_config(f"cs_bar_{selected_parser}")
                )

            st.markdown("---")

            # ì „ëµë³„ ìƒì„¸ ë°ì´í„°
            st.markdown("##### ì „ëµë³„ ìƒì„¸ ë°ì´í„°")

            for strategy_data in parser_strategies:
                strategy_name = strategy_data.get("strategy", "unknown")
                mean_bc = strategy_data.get("mean_bc", 0)
                mean_cs = strategy_data.get("mean_cs")
                std_bc = strategy_data.get("std_bc")
                std_cs = strategy_data.get("std_cs")

                cs_display = f"{mean_cs:.3f}" if mean_cs is not None else "N/A"
                std_bc_display = f"Â±{std_bc:.3f}" if std_bc is not None else ""
                std_cs_display = f"Â±{std_cs:.3f}" if std_cs is not None else ""

                with st.expander(
                    f"**{strategy_name}** | BC: {mean_bc:.3f}{std_bc_display} | CS: {cs_display}{std_cs_display}"
                ):
                    # bc_by_sentence ë°ì´í„° í‘œì‹œ
                    bc_by_sentence = strategy_data.get("bc_by_sentence", [])
                    if bc_by_sentence:
                        bc_df = pd.DataFrame(bc_by_sentence)
                        if "is_boundary" in bc_df.columns:
                            bc_df["is_boundary"] = bc_df["is_boundary"].apply(
                                lambda x: "âœ“ ê²½ê³„" if x else ""
                            )
                        st.dataframe(bc_df, use_container_width=True, hide_index=True, height=300)

                        # CSV ë‹¤ìš´ë¡œë“œ
                        csv_bc = export_df_to_csv(bc_df)
                        st.download_button(
                            label=f"ğŸ“¥ {strategy_name} BC Data CSV",
                            data=csv_bc,
                            file_name=f"bc_{selected_parser}_{strategy_name.lower()}.csv",
                            mime="text/csv",
                            key=f"download_bc_{selected_parser}_{strategy_name}"
                        )
                    else:
                        st.info("bc_by_sentence ë°ì´í„° ì—†ìŒ (CLI ì—°ë™ í•„ìš”)")

    st.markdown("---")

    # Quadrant Guide (ìœ ì§€)
    st.markdown("### ğŸ” BC / CS í•´ì„ ê°€ì´ë“œ")
    st.markdown("""
    | ì§€í‘œ | ì˜ë¯¸ | ì´ìƒì  ê°’ | í•´ì„ |
    |------|------|----------|------|
    | **BC â†‘** | Boundary Clarity | > 0.8 | ì²­í¬ ê²½ê³„ê°€ ì˜ë¯¸ ë‹¨ìœ„ì™€ ì¼ì¹˜ |
    | **CS â†“** | Chunk Stickiness | < 0.3 | ì²­í¬ ë‚´ë¶€ ë¬¸ì¥ë“¤ì´ ë…ë¦½ì  |
    | **std_bc â†“** | BC í‘œì¤€í¸ì°¨ | < 0.1 | ì¼ê´€ëœ ê²½ê³„ í’ˆì§ˆ |
    | **std_cs â†“** | CS í‘œì¤€í¸ì°¨ | < 0.1 | ì¼ê´€ëœ ì‘ì§‘ë„ |

    > ğŸ’¡ **Structuring** ì „ëµì€ ë§ˆí¬ë‹¤ìš´ êµ¬ì¡°(í—¤ë”©, ë¦¬ìŠ¤íŠ¸ ë“±)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„í• í•˜ë¯€ë¡œ CS ê³„ì‚°ì´ ì ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    """)


# =============================================================================
# TAB 3: ì¢…í•© ë¶„ì„
# =============================================================================

with tab_result:
    st.markdown("## ğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼")
    st.markdown("> Parsingê³¼ Chunking ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ íŒŒì´í”„ë¼ì¸ í’ˆì§ˆì„ ì§„ë‹¨í•©ë‹ˆë‹¤.")

    st.markdown("---")

    st.markdown("### ğŸ¯ í•µì‹¬ ë°œê²¬ì‚¬í•­")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        #### Parsing ê´€ì 

        1. **VLMì´ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜**
           - ëŒ€ë¶€ë¶„ì˜ í…ŒìŠ¤íŠ¸ì—ì„œ ìµœì € WER ë‹¬ì„±
           - íŠ¹íˆ ì´ë¯¸ì§€ ê¸°ë°˜ ë¬¸ì„œì—ì„œ ì••ë„ì 

        2. **Trade-off ì¡´ì¬**
           - ì •í™•ë„ â†” ì²˜ë¦¬ ì‹œê°„
           - ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ì—ëŠ” pdfplumber ê³ ë ¤

        3. **ë¬¸ì„œ ìœ í˜•ë³„ ì°¨ì´ í¼**
           - ìŠ¤ìº” ì´ë¯¸ì§€: VLM í•„ìˆ˜
           - ë””ì§€í„¸ PDF: pdfplumberë„ ì¶©ë¶„
        """)

    with col2:
        st.markdown("""
        #### Chunking ê´€ì 

        1. **Semantic Chunking ê¶Œì¥**
           - BCê°€ ê°€ì¥ ë†’ì€ ê²½ê³„ ëª…í™•ë„
           - CSê°€ ë‚®ì€ ë‚´ë¶€ ì˜ì¡´ì„±

        2. **Fixed Chunking ì£¼ì˜**
           - ì˜ë¯¸ ê²½ê³„ ë¬´ì‹œë¡œ BC ë‚®ìŒ
           - RAG ì„±ëŠ¥ ì €í•˜ ìš°ë ¤

        3. **ìµœì  íŒŒë¼ë¯¸í„°**
           - Chunk Size: 400-600
           - Overlap: 50-100
        """)

    st.markdown("---")

    st.markdown("### ğŸš€ ë‹¤ìŒ ë‹¨ê³„")
    st.markdown("""
    | ìš°ì„ ìˆœìœ„ | ì‘ì—… | ëª©ì  |
    |---------|------|------|
    | 1 | Golden Dataset êµ¬ì¶• | í‰ê°€ ì‹ ë¢°ë„ í–¥ìƒ |
    | 2 | VLM SFT í•™ìŠµ | êµ¬ì¡°í™” ì„±ëŠ¥ ê°œì„  |
    | 3 | Semantic Chunking ì ìš© | RAG í’ˆì§ˆ í–¥ìƒ |
    | 4 | ì¶”ê°€ ë¬¸ì„œ ìœ í˜• í…ŒìŠ¤íŠ¸ | ì¼ë°˜í™” ê²€ì¦ |
    """)

    st.markdown("---")
    st.caption(f"VLM Document Parsing Quality Analysis | {VERSION}")
