"""
VLM Document Parsing & Chunking Research Dashboard

"ì–¼ë§ˆë‚˜ ì˜í–ˆëŠ”ê°€"ê°€ ì•„ë‹Œ "ì–´ë””ì„œ, ì™œ êµ¬ì¡°ê°€ ê¹¨ì§€ëŠ”ê°€"ë¥¼ ì§„ë‹¨í•˜ëŠ” ì—°êµ¬ìš© ë„êµ¬

Usage:
    streamlit run src/dashboard_analysis.py
"""

import sys
from pathlib import Path

_src_dir = Path(__file__).parent
if str(_src_dir) not in sys.path:
    sys.path.insert(0, str(_src_dir))

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from typing import Dict, List, Optional
import numpy as np

# =============================================================================
# í˜ì´ì§€ ì„¤ì •
# =============================================================================

st.set_page_config(
    page_title="Parsing & Chunking Research",
    page_icon="ğŸ”¬",
    layout="wide",
)

# =============================================================================
# ìŠ¤íƒ€ì¼ ì„¤ì •
# =============================================================================

st.markdown("""
<style>
    /* ì „ì²´ ë°°ê²½ */
    .stApp { background-color: #FAFAFA; }

    /* í—¤ë” */
    h1, h2, h3 { color: #1a1a2e !important; font-weight: 600 !important; }

    /* ì‚¬ì´ë“œë°” */
    [data-testid="stSidebar"] { background-color: #FFFFFF; border-right: 1px solid #E5E5E5; }
    [data-testid="stSidebar"] h1 { font-size: 1.2rem !important; color: #1a1a2e !important; }

    /* ë©”íŠ¸ë¦­ ì¹´ë“œ */
    [data-testid="stMetric"] {
        background-color: #FFFFFF;
        padding: 1rem;
        border-radius: 8px;
        border: 1px solid #E5E5E5;
    }
    [data-testid="stMetricValue"] { color: #1a1a2e !important; font-size: 1.5rem !important; }
    [data-testid="stMetricLabel"] { color: #666666 !important; }

    /* íƒ­ */
    .stTabs [data-baseweb="tab-list"] { gap: 8px; border-bottom: 1px solid #E5E5E5; }
    .stTabs [data-baseweb="tab"] {
        color: #666666;
        font-weight: 500;
        padding: 0.75rem 1.5rem;
    }
    .stTabs [aria-selected="true"] {
        color: #1a1a2e !important;
        border-bottom: 2px solid #4F46E5 !important;
    }

    /* í…Œì´ë¸” */
    .stDataFrame { border-radius: 8px; }

    /* êµ¬ë¶„ì„  */
    hr { border-color: #E5E5E5; margin: 2rem 0; }

    /* ìº¡ì…˜ */
    .metric-caption { font-size: 0.75rem; color: #888888; margin-top: 0.25rem; }
</style>
""", unsafe_allow_html=True)

# =============================================================================
# ìƒìˆ˜ ë° ìƒ˜í”Œ ë°ì´í„°
# =============================================================================

VERSION = "v0.1.0"

# íŒŒì„œ ìƒ‰ìƒ (ì ˆì œëœ íŒ”ë ˆíŠ¸)
PARSER_COLORS = {
    "VLM (Qwen3-VL)": "#4F46E5",      # Indigo
    "pdfplumber": "#059669",           # Emerald
    "Docling (RapidOCR)": "#D97706",  # Amber
}

# ì²­í‚¹ ì „ëµ ìƒ‰ìƒ
STRATEGY_COLORS = {
    "Fixed": "#6366F1",
    "Sentence": "#10B981",
    "Semantic": "#F59E0B",
    "MoC-style": "#EF4444",
}

# ìƒ˜í”Œ Parsing í…ŒìŠ¤íŠ¸ ë°ì´í„°
PARSING_TEST_DATA = {
    "test_1": {
        "id": "Test 1",
        "name": "í•™ìˆ  ë…¼ë¬¸ (Chain-of-Thought)",
        "doc_type": "PDF - ë‹¤ì¤‘ í˜ì´ì§€, ìˆ˜ì‹/í‘œ í¬í•¨",
        "parsers": {
            "VLM (Qwen3-VL)": {"wer": 0.124, "cer": 0.089, "bleu": 0.847, "latency": 8520},
            "pdfplumber": {"wer": 0.182, "cer": 0.145, "bleu": 0.723, "latency": 1240},
            "Docling (RapidOCR)": {"wer": 0.251, "cer": 0.198, "bleu": 0.652, "latency": 3820},
        },
    },
    "test_2": {
        "id": "Test 2",
        "name": "ì˜ìˆ˜ì¦ (ìŠ¤ìº” ì´ë¯¸ì§€)",
        "doc_type": "ì´ë¯¸ì§€ - ë‹¨ì¼ í˜ì´ì§€, ì§§ì€ í…ìŠ¤íŠ¸",
        "parsers": {
            "VLM (Qwen3-VL)": {"wer": 0.082, "cer": 0.054, "bleu": 0.912, "latency": 2140},
            "pdfplumber": {"wer": 0.456, "cer": 0.387, "bleu": 0.345, "latency": 520},
            "Docling (RapidOCR)": {"wer": 0.153, "cer": 0.112, "bleu": 0.781, "latency": 1580},
        },
    },
    "test_3": {
        "id": "Test 3",
        "name": "ê¸°ìˆ  ë¬¸ì„œ (ì½”ë“œ ë¸”ë¡ í¬í•¨)",
        "doc_type": "PDF - ë‹¤ì¤‘ í˜ì´ì§€, ì½”ë“œ/ë‹¤ì´ì–´ê·¸ë¨",
        "parsers": {
            "VLM (Qwen3-VL)": {"wer": 0.156, "cer": 0.118, "bleu": 0.819, "latency": 12340},
            "pdfplumber": {"wer": 0.223, "cer": 0.178, "bleu": 0.682, "latency": 1820},
            "Docling (RapidOCR)": {"wer": 0.284, "cer": 0.231, "bleu": 0.618, "latency": 5240},
        },
    },
}

# ìƒ˜í”Œ Chunking í…ŒìŠ¤íŠ¸ ë°ì´í„°
CHUNKING_TEST_DATA = {
    "Fixed": {
        "chunks": [
            {"id": 1, "bc": 0.72, "cs": 0.85, "length": 512, "tokens": 128},
            {"id": 2, "bc": 0.68, "cs": 0.91, "length": 512, "tokens": 134},
            {"id": 3, "bc": 0.45, "cs": 0.78, "length": 512, "tokens": 121},
            {"id": 4, "bc": 0.81, "cs": 0.65, "length": 512, "tokens": 142},
            {"id": 5, "bc": 0.38, "cs": 0.92, "length": 512, "tokens": 115},
        ],
        "mean_bc": 0.608, "mean_cs": 0.822,
    },
    "Sentence": {
        "chunks": [
            {"id": 1, "bc": 0.85, "cs": 0.72, "length": 324, "tokens": 82},
            {"id": 2, "bc": 0.79, "cs": 0.68, "length": 456, "tokens": 118},
            {"id": 3, "bc": 0.91, "cs": 0.58, "length": 287, "tokens": 71},
            {"id": 4, "bc": 0.76, "cs": 0.74, "length": 512, "tokens": 135},
            {"id": 5, "bc": 0.88, "cs": 0.61, "length": 398, "tokens": 98},
        ],
        "mean_bc": 0.838, "mean_cs": 0.666,
    },
    "Semantic": {
        "chunks": [
            {"id": 1, "bc": 0.92, "cs": 0.45, "length": 623, "tokens": 156},
            {"id": 2, "bc": 0.87, "cs": 0.52, "length": 412, "tokens": 108},
            {"id": 3, "bc": 0.78, "cs": 0.61, "length": 534, "tokens": 142},
            {"id": 4, "bc": 0.94, "cs": 0.38, "length": 378, "tokens": 95},
        ],
        "mean_bc": 0.878, "mean_cs": 0.490,
    },
}


# =============================================================================
# ì°¨íŠ¸ ìƒì„± í•¨ìˆ˜
# =============================================================================

def create_thin_bar_chart(data: Dict, metric: str, title: str,
                          lower_is_better: bool = False) -> go.Figure:
    """ì–‡ê³  ë‹¨ì •í•œ ê°€ë¡œí˜• Bar Chart"""

    parsers = list(data["parsers"].keys())
    values = [data["parsers"][p][metric] for p in parsers]
    colors = [PARSER_COLORS.get(p, "#888") for p in parsers]

    fig = go.Figure()

    fig.add_trace(go.Bar(
        y=parsers,
        x=values,
        orientation='h',
        marker_color=colors,
        marker_line_width=0,
        text=[f"{v:.3f}" if metric != "latency" else f"{v:,}ms" for v in values],
        textposition="outside",
        textfont=dict(size=11, color="#666"),
    ))

    direction = "â† Lower is better" if lower_is_better else "Higher is better â†’"

    fig.update_layout(
        title=dict(text=f"{title}", font=dict(size=13, color="#1a1a2e"), x=0),
        height=160,
        margin=dict(l=0, r=60, t=35, b=5),
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        font=dict(size=11, color="#666"),
        xaxis=dict(showgrid=False, showticklabels=False, zeroline=False),
        yaxis=dict(showgrid=False, tickfont=dict(size=10)),
        showlegend=False,
        annotations=[
            dict(
                text=direction, x=1, y=-0.15, xref="paper", yref="paper",
                showarrow=False, font=dict(size=9, color="#999"),
                xanchor="right"
            )
        ]
    )

    return fig


def hex_to_rgba(hex_color: str, alpha: float = 0.1) -> str:
    """Hex ìƒ‰ìƒì„ rgba ë¬¸ìì—´ë¡œ ë³€í™˜"""
    hex_color = hex_color.lstrip('#')
    r = int(hex_color[0:2], 16)
    g = int(hex_color[2:4], 16)
    b = int(hex_color[4:6], 16)
    return f"rgba({r},{g},{b},{alpha})"


def create_radar_chart(all_data: Dict) -> go.Figure:
    """íŒŒì„œë³„ ì „ì²´ ì„±ëŠ¥ Radar Chart"""

    metrics = ["WER", "CER", "BLEU", "Latency"]

    fig = go.Figure()

    # íŒŒì„œë³„ í‰ê·  ê³„ì‚° ë° ì •ê·œí™”
    for parser in list(PARSER_COLORS.keys()):
        values = []
        for metric_key, metric_name in [("wer", "WER"), ("cer", "CER"),
                                         ("bleu", "BLEU"), ("latency", "Latency")]:
            avg = np.mean([
                test["parsers"][parser][metric_key]
                for test in all_data.values()
            ])

            # ì •ê·œí™” (0-1 ìŠ¤ì¼€ì¼ë¡œ, ë‚®ì„ìˆ˜ë¡ ì¢‹ì€ ê²ƒì€ ë°˜ì „)
            if metric_key in ["wer", "cer"]:
                normalized = 1 - min(avg, 1)  # ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ â†’ ë°˜ì „
            elif metric_key == "latency":
                normalized = 1 - min(avg / 15000, 1)  # 15ì´ˆ ê¸°ì¤€ ì •ê·œí™”
            else:
                normalized = avg  # BLEUëŠ” ê·¸ëŒ€ë¡œ

            values.append(normalized)

        values.append(values[0])  # ë‹«ê¸°

        # 90% íˆ¬ëª… (alpha=0.1), ì„ ë§Œ ì§„í•˜ê²Œ (width=3)
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=metrics + [metrics[0]],
            name=parser,
            line=dict(color=PARSER_COLORS[parser], width=3),
            fill='toself',
            fillcolor=hex_to_rgba(PARSER_COLORS[parser], 0.1),
        ))

    fig.update_layout(
        polar=dict(
            radialaxis=dict(visible=True, range=[0, 1], showticklabels=False, gridcolor="#E5E5E5"),
            angularaxis=dict(tickfont=dict(size=11, color="#666"), gridcolor="#E5E5E5"),
            bgcolor="rgba(0,0,0,0)",
        ),
        showlegend=True,
        legend=dict(orientation="h", yanchor="bottom", y=-0.2, xanchor="center", x=0.5,
                   font=dict(size=10)),
        height=350,
        margin=dict(l=60, r=60, t=30, b=60),
        paper_bgcolor="rgba(0,0,0,0)",
    )

    return fig


def create_bc_cs_scatter(chunking_data: Dict) -> go.Figure:
    """BC vs CS Scatter Plot (í•µì‹¬ ì‹œê°í™”)"""

    fig = go.Figure()

    for strategy, data in chunking_data.items():
        bc_values = [c["bc"] for c in data["chunks"]]
        cs_values = [c["cs"] for c in data["chunks"]]

        fig.add_trace(go.Scatter(
            x=bc_values,
            y=cs_values,
            mode='markers',
            name=strategy,
            marker=dict(
                size=12,
                color=STRATEGY_COLORS.get(strategy, "#888"),
                line=dict(width=1, color="white"),
                opacity=0.8,
            ),
            hovertemplate=f"<b>{strategy}</b><br>BC: %{{x:.2f}}<br>CS: %{{y:.2f}}<extra></extra>",
        ))

    # Quadrant ì˜ì—­ í‘œì‹œ (ë°°ê²½)
    fig.add_shape(type="rect", x0=0.5, x1=1, y0=0, y1=0.5,
                  fillcolor="rgba(16, 185, 129, 0.05)", line_width=0)  # ì´ìƒì  ì˜ì—­
    fig.add_shape(type="rect", x0=0, x1=0.5, y0=0.5, y1=1,
                  fillcolor="rgba(239, 68, 68, 0.05)", line_width=0)  # ë¬¸ì œ ì˜ì—­

    # ê°€ì´ë“œ ë¼ì¸
    fig.add_hline(y=0.5, line_dash="dot", line_color="#ccc", line_width=1)
    fig.add_vline(x=0.5, line_dash="dot", line_color="#ccc", line_width=1)

    # Quadrant ë¼ë²¨
    annotations = [
        dict(x=0.75, y=0.25, text="ì´ìƒì <br>(BCâ†‘ CSâ†“)", showarrow=False,
             font=dict(size=9, color="#059669"), opacity=0.7),
        dict(x=0.25, y=0.75, text="Over-merge<br>(BCâ†“ CSâ†‘)", showarrow=False,
             font=dict(size=9, color="#DC2626"), opacity=0.7),
        dict(x=0.75, y=0.75, text="Fragmentation<br>(BCâ†‘ CSâ†‘)", showarrow=False,
             font=dict(size=9, color="#D97706"), opacity=0.7),
        dict(x=0.25, y=0.25, text="Structural<br>Failure", showarrow=False,
             font=dict(size=9, color="#6B7280"), opacity=0.7),
    ]

    fig.update_layout(
        title=dict(text="BCâ€“CS Distribution by Strategy", font=dict(size=14, color="#1a1a2e"), x=0),
        xaxis=dict(title="Boundary Clarity (BC) â†’", range=[0, 1],
                   gridcolor="#E5E5E5", zeroline=False, tickfont=dict(size=10)),
        yaxis=dict(title="Chunk Stickiness (CS) â†“", range=[0, 1],
                   gridcolor="#E5E5E5", zeroline=False, tickfont=dict(size=10)),
        height=450,
        margin=dict(l=60, r=30, t=50, b=50),
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0,
                   font=dict(size=10)),
        annotations=annotations,
    )

    return fig


def create_overview_grouped_bar(all_data: Dict, metric: str, title: str,
                                 lower_is_better: bool = False) -> go.Figure:
    """ì „ì²´ í…ŒìŠ¤íŠ¸ ë¹„êµ Grouped Bar Chart"""

    test_ids = [d["id"] for d in all_data.values()]

    fig = go.Figure()

    for parser, color in PARSER_COLORS.items():
        values = [test["parsers"][parser][metric] for test in all_data.values()]

        fig.add_trace(go.Bar(
            name=parser,
            x=test_ids,
            y=values,
            marker_color=color,
            marker_line_width=0,
            text=[f"{v:.2f}" if metric != "latency" else f"{v/1000:.1f}s" for v in values],
            textposition="outside",
            textfont=dict(size=9),
            width=0.25,
        ))

    direction = "â†“ Lower is better" if lower_is_better else "â†‘ Higher is better"

    fig.update_layout(
        title=dict(text=f"{title} ({direction})", font=dict(size=13, color="#1a1a2e"), x=0),
        barmode="group",
        height=280,
        margin=dict(l=40, r=20, t=50, b=40),
        paper_bgcolor="rgba(0,0,0,0)",
        plot_bgcolor="rgba(0,0,0,0)",
        font=dict(size=10, color="#666"),
        xaxis=dict(showgrid=False, tickfont=dict(size=10)),
        yaxis=dict(gridcolor="#E5E5E5", gridwidth=0.5, zeroline=False),
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="left", x=0,
                   font=dict(size=9)),
        bargap=0.3,
        bargroupgap=0.1,
    )

    return fig


# =============================================================================
# ë©”ì¸ ì•±
# =============================================================================

# ìƒìœ„ íƒ­ êµ¬ì¡°
tab_parsing, tab_chunking, tab_result = st.tabs([
    "ğŸ” Parsing Test",
    "ğŸ“¦ Chunking Test",
    "ğŸ“Š Result (ì¢…í•© ë¶„ì„)"
])


# =============================================================================
# TAB 1: Parsing Test
# =============================================================================

with tab_parsing:

    # --- Sidebar ---
    with st.sidebar:
        st.markdown("# Data Parsing Research")
        st.markdown("---")

        test_mode = st.selectbox(
            "Test Mode",
            options=["Sample Data", "File Upload"],
            help="Sample Data: ì‚¬ì „ ì •ì˜ëœ í…ŒìŠ¤íŠ¸ 3ê±´ ì‚¬ìš©"
        )

        if test_mode == "File Upload":
            st.markdown("#### Input Document")
            uploaded_file = st.file_uploader(
                "ë¬¸ì„œ ì—…ë¡œë“œ",
                type=["pdf", "png", "jpg"],
                help="PDF ë˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼"
            )

            st.markdown("#### Ground Truth")
            gt_text = st.text_area(
                "ì •ë‹µ í…ìŠ¤íŠ¸ ì…ë ¥",
                height=150,
                placeholder="Ground Truth í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."
            )

            if st.button("í…ŒìŠ¤íŠ¸ ì‹¤í–‰", type="primary", use_container_width=True):
                st.info("ğŸš§ File Upload ëª¨ë“œëŠ” Golden Dataset êµ¬ì¶• í›„ í™œì„±í™” ì˜ˆì •")

        st.markdown("---")
        st.caption(f"Version: {VERSION} (Parsing Research)")

    # --- Main Content ---
    st.markdown("## Parsing Test Results")

    # A. Metrics Overview
    st.markdown("### ğŸ“ Metrics Overview")

    st.markdown("""
    <div style="background-color: #F5F5F5; padding: 1.5rem; border-radius: 8px; margin-bottom: 1rem;">
        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 2rem;">
            <div>
                <p style="font-size: 1.1rem; font-weight: 600; color: #1a1a2e; margin-bottom: 0.5rem;">
                    WER (Word Error Rate) <span style="color: #059669; font-size: 0.9rem;">â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ</span>
                </p>
                <ul style="color: #555; margin: 0; padding-left: 1.2rem; font-size: 0.9rem;">
                    <li>Mecab Tokenizer ê¸°ë°˜ ë‹¨ì–´ ë‹¨ìœ„ ì˜¤ë¥˜ìœ¨</li>
                    <li>ì‚½ì…/ì‚­ì œ/ëŒ€ì²´ ì˜¤ë¥˜ë¥¼ ì¢…í•© ì¸¡ì •</li>
                </ul>

                <p style="font-size: 1.1rem; font-weight: 600; color: #1a1a2e; margin-top: 1rem; margin-bottom: 0.5rem;">
                    CER (Character Error Rate) <span style="color: #059669; font-size: 0.9rem;">â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ</span>
                </p>
                <ul style="color: #555; margin: 0; padding-left: 1.2rem; font-size: 0.9rem;">
                    <li>ë¬¸ì ë‹¨ìœ„ ì˜¤ë¥˜ìœ¨</li>
                    <li>Error Injection: ì–´ë–¤ ë¬¸ìê°€ ëˆ„ë½/ì¶”ê°€/ë³€ê²½ë˜ì—ˆëŠ”ì§€ ì¶”ì </li>
                </ul>
            </div>
            <div>
                <p style="font-size: 1.1rem; font-weight: 600; color: #1a1a2e; margin-bottom: 0.5rem;">
                    BLEU Score <span style="color: #D97706; font-size: 0.9rem;">â†‘ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ (ë³´ì¡°)</span>
                </p>
                <ul style="color: #555; margin: 0; padding-left: 1.2rem; font-size: 0.9rem;">
                    <li>ë¬¸ì¥ ìœ ì‚¬ë„ê°€ ì•„ë‹Œ í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ í™•ì¸ìš©</li>
                    <li>n-gram ê¸°ë°˜ ì •ë°€ë„ ì¸¡ì •</li>
                </ul>

                <p style="font-size: 1.1rem; font-weight: 600; color: #1a1a2e; margin-top: 1rem; margin-bottom: 0.5rem;">
                    Latency <span style="color: #059669; font-size: 0.9rem;">â†“ ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ</span>
                </p>
                <ul style="color: #555; margin: 0; padding-left: 1.2rem; font-size: 0.9rem;">
                    <li>ë¬¸ì„œ 1ê±´ ê¸°ì¤€ Parsing ì²˜ë¦¬ ì‹œê°„</li>
                    <li>ë‹¨ìœ„: milliseconds (ms)</li>
                </ul>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("---")

    # B. í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ê°œìš”
    st.markdown("### ğŸ“ˆ Global Performance Summary")

    col_table, col_radar = st.columns([1, 1])

    with col_table:
        # ì „ì²´ ê²°ê³¼ í…Œì´ë¸”
        table_rows = []
        for test_id, test_data in PARSING_TEST_DATA.items():
            for parser, metrics in test_data["parsers"].items():
                table_rows.append({
                    "Test": test_data["id"],
                    "Parser": parser,
                    "WER": f"{metrics['wer']:.3f}",
                    "CER": f"{metrics['cer']:.3f}",
                    "BLEU": f"{metrics['bleu']:.3f}",
                    "Latency": f"{metrics['latency']:,}ms",
                })

        df = pd.DataFrame(table_rows)
        st.dataframe(df, use_container_width=True, hide_index=True, height=350)

    with col_radar:
        st.plotly_chart(create_radar_chart(PARSING_TEST_DATA), use_container_width=True)

    # í•˜ë‹¨ 4ê°œ ì°¨íŠ¸ (Z ë ˆì´ì•„ì›ƒ)
    st.markdown("#### Metrics Comparison")

    row1_col1, row1_col2 = st.columns(2)
    row2_col1, row2_col2 = st.columns(2)

    with row1_col1:
        st.plotly_chart(
            create_overview_grouped_bar(PARSING_TEST_DATA, "wer", "WER", lower_is_better=True),
            use_container_width=True
        )

    with row1_col2:
        st.plotly_chart(
            create_overview_grouped_bar(PARSING_TEST_DATA, "cer", "CER", lower_is_better=True),
            use_container_width=True
        )

    with row2_col1:
        st.plotly_chart(
            create_overview_grouped_bar(PARSING_TEST_DATA, "bleu", "BLEU", lower_is_better=False),
            use_container_width=True
        )

    with row2_col2:
        st.plotly_chart(
            create_overview_grouped_bar(PARSING_TEST_DATA, "latency", "Latency", lower_is_better=True),
            use_container_width=True
        )

    st.markdown("---")

    # C. ê°œë³„ í…ŒìŠ¤íŠ¸ ìƒì„¸ ê²°ê³¼
    st.markdown("### ğŸ”¬ Detailed Test Analysis")

    for test_id, test_data in PARSING_TEST_DATA.items():

        st.markdown(f"#### {test_data['id']}: {test_data['name']}")
        st.caption(f"ğŸ“„ {test_data['doc_type']}")

        # ë©”íŠ¸ë¦­ ì¹´ë“œ (ì‘ê²Œ)
        m1, m2, m3, m4 = st.columns(4)

        # VLM ê¸°ì¤€ìœ¼ë¡œ í‘œì‹œ (ëŒ€í‘œ íŒŒì„œ)
        vlm_metrics = test_data["parsers"]["VLM (Qwen3-VL)"]

        m1.metric("WER", f"{vlm_metrics['wer']:.3f}", help="VLM ê¸°ì¤€")
        m2.metric("CER", f"{vlm_metrics['cer']:.3f}", help="VLM ê¸°ì¤€")
        m3.metric("BLEU", f"{vlm_metrics['bleu']:.3f}", help="VLM ê¸°ì¤€")
        m4.metric("Latency", f"{vlm_metrics['latency']:,}ms", help="VLM ê¸°ì¤€")

        # ê°€ë¡œí˜• Bar Chart
        chart_cols = st.columns(4)

        with chart_cols[0]:
            st.plotly_chart(
                create_thin_bar_chart(test_data, "wer", "WER", lower_is_better=True),
                use_container_width=True
            )

        with chart_cols[1]:
            st.plotly_chart(
                create_thin_bar_chart(test_data, "cer", "CER", lower_is_better=True),
                use_container_width=True
            )

        with chart_cols[2]:
            st.plotly_chart(
                create_thin_bar_chart(test_data, "bleu", "BLEU", lower_is_better=False),
                use_container_width=True
            )

        with chart_cols[3]:
            st.plotly_chart(
                create_thin_bar_chart(test_data, "latency", "Latency", lower_is_better=True),
                use_container_width=True
            )

        st.markdown("---")

    # D. ê²°ë¡ 
    st.markdown("### ğŸ“ Parsing Analysis Conclusion")

    st.markdown("""
    #### íŒŒì„œë³„ íŠ¹ì§• ìš”ì•½

    | Parser | ê°•ì  | ì•½ì  | ê¶Œì¥ ì‚¬ìš©ì²˜ |
    |--------|------|------|------------|
    | **VLM (Qwen3-VL)** | êµ¬ì¡°í™” ì •í™•ë„ ë†’ìŒ, ì´ë¯¸ì§€ ì¸ì‹ ìš°ìˆ˜ | ì²˜ë¦¬ ì‹œê°„ ê¹€ | ë³µì¡í•œ ë¬¸ì„œ, ìŠ¤ìº” ì´ë¯¸ì§€ |
    | **pdfplumber** | ë¹ ë¥¸ ì²˜ë¦¬, ë””ì§€í„¸ PDFì— ì•ˆì •ì  | ì´ë¯¸ì§€ ê¸°ë°˜ ë¬¸ì„œ ì·¨ì•½ | í…ìŠ¤íŠ¸ ê¸°ë°˜ ë””ì§€í„¸ PDF |
    | **Docling (RapidOCR)** | ë²”ìš©ì„±, ì¤‘ê°„ ì„±ëŠ¥ | íŠ¹ì¶œë‚œ ê°•ì  ì—†ìŒ | ì¼ë°˜ì ì¸ OCR í•„ìš” ì‹œ |

    #### ì—ëŸ¬ ìœ í˜• ê²½í–¥
    - **VLM**: ìˆ˜ì‹/íŠ¹ìˆ˜ë¬¸ìì—ì„œ ê°„í—ì  ì˜¤ë¥˜
    - **pdfplumber**: ë ˆì´ì•„ì›ƒ ë³µì¡ë„ì— ë¯¼ê°
    - **Docling**: ì €í•´ìƒë„ ì´ë¯¸ì§€ì—ì„œ ì¸ì‹ë¥  ì €í•˜

    #### Golden Dataset êµ¬ì¶• ì‹œ ê¸°ëŒ€ íš¨ê³¼
    - ë¬¸ì„œ ìœ í˜•ë³„ ìµœì  íŒŒì„œ ìë™ ì„ íƒ ê¸°ì¤€ ìˆ˜ë¦½
    - SFTë¥¼ í†µí•œ VLM ì„±ëŠ¥ ê°œì„  ëª©í‘œì¹˜ ì„¤ì •
    """)


# =============================================================================
# TAB 2: Chunking Test
# =============================================================================

with tab_chunking:

    # --- Sidebar ---
    with st.sidebar:
        st.markdown("# Chunking Strategy Research")
        st.markdown("---")

        selected_strategies = st.multiselect(
            "Chunking Strategies",
            options=list(CHUNKING_TEST_DATA.keys()),
            default=list(CHUNKING_TEST_DATA.keys()),
        )

        st.markdown("#### Parameters")
        chunk_size = st.slider("Chunk Size", 256, 1024, 512, 64)
        chunk_overlap = st.slider("Overlap", 0, 128, 50, 10)

        st.markdown("---")
        st.caption(f"Version: {VERSION} (Chunking Research)")

    # --- Main Content ---
    st.markdown("## Chunking Quality Analysis")
    st.markdown("""
    > Chunking TestëŠ” ì„±ëŠ¥ ë¹„êµê°€ ì•„ë‹ˆë¼ **"êµ¬ì¡° ì§„ë‹¨"**ì´ ëª©ì ì…ë‹ˆë‹¤.
    > ì²­í¬ ê²½ê³„ì˜ íƒ€ë‹¹ì„±(BC)ê³¼ ë‚´ë¶€ ì‘ì§‘ë„(CS)ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    """)

    st.markdown("---")

    # A. Chunking Quality Metrics
    st.markdown("### ğŸ“ Chunking Quality Metrics")

    with st.expander("BC / CS Metrics ì •ì˜", expanded=False):
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            **Boundary Clarity (BC)**
            - ì²­í¬ ê°„ **ì˜ë¯¸ì  ë…ë¦½ì„±** ì¸¡ì •
            - ê²½ê³„ ìœ„ì¹˜ê°€ ì˜ë¯¸ì ìœ¼ë¡œ íƒ€ë‹¹í•œì§€ í‰ê°€
            - PPL(q|d) / PPL(q) ê¸°ë°˜ ê³„ì‚°
            - *ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ (0~1)*
            """)

        with col2:
            st.markdown("""
            **Chunk Stickiness (CS)**
            - ì²­í¬ ë‚´ë¶€ **ì˜ë¯¸ ì‘ì§‘ë„** ì¸¡ì •
            - ë‚´ë¶€ ìš”ì†Œë“¤ì´ ì–¼ë§ˆë‚˜ ê¸´ë°€íˆ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€
            - Structural Entropy ê¸°ë°˜ ê³„ì‚°
            - *ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ (ì´ìƒì : 0ì— ê°€ê¹Œì›€)*
            """)

    st.markdown("---")

    # B. BC / CS Distribution Overview
    st.markdown("### ğŸ“Š BCâ€“CS Distribution Overview")

    # KPI ì¹´ë“œ
    kpi_cols = st.columns(len(selected_strategies) + 1)

    with kpi_cols[0]:
        total_chunks = sum(len(CHUNKING_TEST_DATA[s]["chunks"]) for s in selected_strategies)
        st.metric("Total Chunks", total_chunks)

    for i, strategy in enumerate(selected_strategies):
        data = CHUNKING_TEST_DATA[strategy]
        with kpi_cols[i + 1]:
            st.metric(
                strategy,
                f"BC: {data['mean_bc']:.2f}",
                f"CS: {data['mean_cs']:.2f}",
                delta_color="off"
            )

    # BC-CS Scatter Plot (í•µì‹¬)
    filtered_data = {s: CHUNKING_TEST_DATA[s] for s in selected_strategies}
    st.plotly_chart(create_bc_cs_scatter(filtered_data), use_container_width=True)

    st.markdown("---")

    # C. Chunking Failure Pattern Analysis
    st.markdown("### ğŸ” Failure Pattern Analysis")

    st.markdown("""
    **Quadrant í•´ì„ ê°€ì´ë“œ**

    | ì˜ì—­ | BC | CS | ì˜ë¯¸ | ì¡°ì¹˜ |
    |------|----|----|------|------|
    | ğŸŸ¢ ì´ìƒì  | High | Low | ê²½ê³„ ëª…í™•, ë‚´ë¶€ ë…ë¦½ì  | ìœ ì§€ |
    | ğŸŸ¡ Fragmentation | High | High | ê³¼ë„í•œ ë¶„í•  | Chunk í¬ê¸° ì¦ê°€ |
    | ğŸ”´ Over-merge | Low | High | ê³¼ë„í•œ ë³‘í•© | Chunk í¬ê¸° ê°ì†Œ |
    | âš« Structural Failure | Low | Low | êµ¬ì¡° ìì²´ ë¬¸ì œ | ì „ëµ ì¬ê²€í†  |
    """)

    # ì „ëµë³„ ìƒì„¸ ë¶„ì„
    for strategy in selected_strategies:
        with st.expander(f"ğŸ“¦ {strategy} Strategy Details"):
            chunks = CHUNKING_TEST_DATA[strategy]["chunks"]

            chunk_df = pd.DataFrame(chunks)
            chunk_df["Quadrant"] = chunk_df.apply(
                lambda r: "ì´ìƒì " if r["bc"] >= 0.5 and r["cs"] < 0.5
                else "Fragmentation" if r["bc"] >= 0.5 and r["cs"] >= 0.5
                else "Over-merge" if r["bc"] < 0.5 and r["cs"] >= 0.5
                else "Structural Failure",
                axis=1
            )

            st.dataframe(chunk_df, use_container_width=True, hide_index=True)

    st.markdown("---")

    # D. Chunking Summary
    st.markdown("### ğŸ“ Chunking Strategy Summary")

    st.markdown("""
    #### ì „ëµë³„ íŠ¹ì§•

    | Strategy | BC (mean) | CS (mean) | íŠ¹ì§• |
    |----------|-----------|-----------|------|
    | **Fixed** | 0.61 | 0.82 | ì¼ì •í•œ í¬ê¸°, ì˜ë¯¸ ê²½ê³„ ë¬´ì‹œ |
    | **Sentence** | 0.84 | 0.67 | ë¬¸ì¥ ë‹¨ìœ„, ì ì ˆí•œ ê· í˜• |
    | **Semantic** | 0.88 | 0.49 | ì˜ë¯¸ ë‹¨ìœ„, ê°€ì¥ ë†’ì€ BC |

    #### Retrieval ì˜í–¥ í•´ì„
    - **BCê°€ ë†’ì€ ì „ëµ**: ê²€ìƒ‰ ì‹œ ê´€ë ¨ ì—†ëŠ” ì»¨í…ìŠ¤íŠ¸ í˜¼ì… ê°ì†Œ
    - **CSê°€ ë‚®ì€ ì „ëµ**: ì²­í¬ ë‚´ ì •ë³´ ì¤‘ë³µ ê°ì†Œ, íš¨ìœ¨ì  ì¸ë±ì‹±
    - **ê¶Œì¥**: Semantic ë˜ëŠ” Sentence ê¸°ë°˜ ì „ëµ
    """)


# =============================================================================
# TAB 3: Result (ì¢…í•© ë¶„ì„)
# =============================================================================

with tab_result:

    st.markdown("## ğŸ“Š ì¢…í•© ë¶„ì„ ê²°ê³¼")

    st.markdown("""
    > ì´ ì„¹ì…˜ì€ Parsingê³¼ Chunking ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ì „ì²´ íŒŒì´í”„ë¼ì¸ì˜ í’ˆì§ˆì„ ì§„ë‹¨í•©ë‹ˆë‹¤.
    """)

    st.markdown("---")

    st.markdown("### ğŸ¯ í•µì‹¬ ë°œê²¬ì‚¬í•­")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        #### Parsing ê´€ì 

        1. **VLMì´ ì „ë°˜ì ìœ¼ë¡œ ìš°ìˆ˜**
           - 3ê°œ í…ŒìŠ¤íŠ¸ ì¤‘ 3ê°œì—ì„œ ìµœì € WER
           - íŠ¹íˆ ì´ë¯¸ì§€ ê¸°ë°˜ ë¬¸ì„œì—ì„œ ì••ë„ì 

        2. **Trade-off ì¡´ì¬**
           - ì •í™•ë„ â†” ì²˜ë¦¬ ì‹œê°„
           - ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ì—ëŠ” pdfplumber ê³ ë ¤

        3. **ë¬¸ì„œ ìœ í˜•ë³„ ì°¨ì´ í¼**
           - ìŠ¤ìº” ì´ë¯¸ì§€: VLM í•„ìˆ˜
           - ë””ì§€í„¸ PDF: pdfplumberë„ ì¶©ë¶„
        """)

    with col2:
        st.markdown("""
        #### Chunking ê´€ì 

        1. **Semantic Chunking ê¶Œì¥**
           - BC 0.88ë¡œ ê°€ì¥ ë†’ì€ ê²½ê³„ ëª…í™•ë„
           - CS 0.49ë¡œ ë‚®ì€ ë‚´ë¶€ ì˜ì¡´ì„±

        2. **Fixed Chunking ì£¼ì˜**
           - ì˜ë¯¸ ê²½ê³„ ë¬´ì‹œë¡œ BC ë‚®ìŒ
           - RAG ì„±ëŠ¥ ì €í•˜ ìš°ë ¤

        3. **ìµœì  íŒŒë¼ë¯¸í„°**
           - Chunk Size: 400-600
           - Overlap: 50-100
        """)

    st.markdown("---")

    st.markdown("### ğŸš€ ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥ì‚¬í•­")

    st.markdown("""
    | ìš°ì„ ìˆœìœ„ | ì‘ì—… | ëª©ì  |
    |---------|------|------|
    | 1 | Golden Dataset êµ¬ì¶• | í‰ê°€ ì‹ ë¢°ë„ í–¥ìƒ |
    | 2 | VLM SFT í•™ìŠµ | êµ¬ì¡°í™” ì„±ëŠ¥ ê°œì„  |
    | 3 | Semantic Chunking íŒŒì´í”„ë¼ì¸ ì ìš© | RAG í’ˆì§ˆ í–¥ìƒ |
    | 4 | ì¶”ê°€ ë¬¸ì„œ ìœ í˜• í…ŒìŠ¤íŠ¸ | ì¼ë°˜í™” ì„±ëŠ¥ ê²€ì¦ |
    """)

    st.markdown("---")
    st.caption(f"VLM Document Parsing Research Dashboard | {VERSION}")
